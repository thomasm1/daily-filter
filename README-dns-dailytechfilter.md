Route 53 DNS. Route 53 is Amazon's managed DNS, or domain name system, service. Before we jump into the specifics of Route 53, I want to set the right expectations for this course. Let me start off by saying that you do not need a deep understanding of DNS going into this course. If you do consider yourself a DNS expert, that's awesome and I think you're really going to enjoy this course because we're going to get into some deep DNS topics, but even if you consider yourself a DNS novice, I'm going to bring you up to speed on everything you need to know for Route 53. In order to get the most out of Route 53, you have to understand DNS terms and concepts. Route 53 does not abstract away or hide many elements of DNS at all. This is different than the way many other AWS services work. Just to give some examples, you can use the AWS Elastic Block Store, or EBS service, without having to understand block storage concepts because AWS abstracts those concepts and hides them behind a nice user friendly interface. You can EC2 instances, which are just virtual machines, without having to understand how a virtual machine hypervisor works. Route 53 is not like that. If you want to learn Route 53, you must also understand DNS. So in this module, I'm going to get you up to speed, not only on how DNS works, but also why it's designed the way it is. I'll introduce you to DNS terms and concepts, as well as where Route 53 fits into the internet's global domain system. Lastly, I'll introduce you to a command line utility called nslookup that we're going to use throughout this course to test our Route 53 configurations. This course is part of a three course series covering three key AWS networking topics, virtual private cloud, elastic load balancing, and, of course, Route 53 DNS. These three courses, although related, are all independent of one another. So you can watch them in any order you'd like. As with the other courses in the AWS Networking Deep Dive series, this course features a lot of hands on labs. If you want to follow along with these labs, here are the prerequisites. First and foremost, you must comfortable with the command line. AWS involves a lot of pointing and clicking in the console, but when it comes to configuring, and particularly when it comes to testing Route 53, having a level of comfort with the command line is going to be a big help. Which command line specifically? It doesn't matter. If you're familiar with the Windows command line, PowerShell or a Mac OS or Linux shell, you will be absolutely fine following along with this course. Second, you must know how to create and configure VPCs in depth. I'm talking about creating a new VPC from scratch, adding new subnets, internet gateways, and setting up route tables. Although this isn't strictly required to use Route 53, it is required to follow along. You'll also need to know how to spin up Linux-based EC2 instances using a particular Amazon machine image, and last but not least, you'll also need to know how to secure shell into those instances. You don't need to be a Linux expert, or even a novice, but you do need to at least know how to SSH into a Linux EC2 instance. Now if you don't meet those last three requirements, please watch the first deep dive course in the series covering Virtual Private Cloud, VPC. In that course, I walk you through those prerequisite topics in depth, hence the term deep dive. And to make it easy for you, you can just type in the link you see here on the link or you can search for the course by name, whichever is easier for you. Otherwise, keep watching and we'll dive right into the heart of DNS, the domain name.

Understanding Domain Names
When most people think of DNS, the Domain Name System, they think of a very specific use case. You want to visit a website and in order to do so, you have to connect to its IP address. But IP addresses are hard to remember. Names, however, are easy to remember. So DNS creates a mapping between an easy to remember name and a hard to remember IP address. Okay, you've probably heard this description 1000 times, and it's understandable because this is the most familiar use case for DNS, but it's not the only use case. You've probably heard the old phone book analogy, you know, in the same way that you look up a person by name and find their phone number with DNS, you look up a domain name and the system returns an IP address. That's not a bad or inaccurate analogy, but it only tells one very small part of the story. When you look up a person's name in a phone book, you may not necessarily be looking for a phone number. For example, you may look up John Smith in order to find not just his phone number, but this street address. Or perhaps you know John Smith is married and you want to send a card to him and his wife, but you don't know her name, so you look in the phone book to see if her name is listed along with his. You get the idea. The point here is that when you're looking up someone by name, you're looking for some specific type of information. To put this in DNS terms, you're looking up a name to locate a type of a resource. That type of resources may be a phone number, a street address or something else. What makes the phone book useful is that it gives you a value associated with that name and resource type. This is almost exactly the way DNS works, in fact, you can think of DNS as a database. Take, for example the domain name example. com. The resource type may be an IP address, which is specified by A as in address. Together example. com and the resource type A form a pairing. DNS associates this pairing with some value called the resource data, which in this case would be an IP address. Together, the domain name, resource type, and resource data form part of a resource record. I say part of a resource record because it does contain other data as well, but that data isn't going to make sense until we get some more context. For now, just remember that a resource record contains three elements, a domain name, a resource type, and resource data. Now not surprisingly, the domain name is at the heart of the domain name system. But what exactly is a domain name? Now I don't mean to insult your intelligence here, you know a domain name when you see one, but for this course we need to carefully define the term because it can have several different meanings, depending on the context. First of all, I want you to clear your mind of any preconceptions you may have regarding the term domain name. When you think of a domain name, you might think of example. com or company. pri, and indeed these are valid domain names, but more generally, you may think of a domain name in the format of string. string, and that's pretty close to how I want you to start thinking about it. In fact, believe or not, string. string is a valid domain name. A domain name is just a list of labels separated by dots, but the labels are not arbitrary, they're organized into a tree structure. To illustrate, let's take one of the domain names I just mentioned, example. com, only this time we'll add the word web to it so that it reads web. example. com. If we organize this into a tree structure, you've got the right most label of com and the middle label of example as a child node underneath it. Finally, at the very bottom node, you have the left most label, which is web. Now just to clarify, I'm using the term node here to specify a data point on the tree, the word node does not refer to a host or IP address or any other kind of network resource, it is literally just the name of a location on the tree. Now there is one more label, which is actually a null zero length label at the root of the tree. This is called the root label and it's often represented as just a dot. By the way, this tree looks unbalance right now because we're going to add more to this in a moment. I just want to keep each node in the same place to avoid confusion. So this brings us back to the original question. What is a domain name? According to RFC 1034, which lays out the original DNS specification, the domain name of a node is the list of labels on the path from the node to the root of the tree. Okay, let me read that again. The domain name of a node is the list of labels on the path from the node to the root of the tree. In other words, a domain name describes a node on the tree by tracing the node all the way back to the root. Every label along that path becomes part of the domain name. The takeaway here is that we can describe a node by its domain name and for brevity, I'll also sometimes refer to a domain name as just a domain. Now the root of the tree is represented by a dot, the domain name of the root is literally just dot. The domain name of the com node is com dot. The domain name of the example node is example dot com dot. Finally the domain name for the node labeled web is web dot example dot com dot. Now you rarely see domain names written with the trailing dot, and it's perfectly fine to leave it out, but just remember, that even if you don't see it, it's always implied. Route 53 actually makes no distinction, so you can use web dot example dot com dot or just web dot example dot com. It's your choice. Now many people, including myself, have gotten into a habit of calling this a host name or a fully qualified domain name or FQND, and that's not wrong, but it is potentially confusing. So in this course, I'm going to avoid those terms and instead use the term domain name, as RFC 1034 defines it. Okay, just to make this a little more like a tree, let's take another one of the domain names I've mentioned, which is company. pri. Directly under the root node, you have a node labeled pri and under that you have a node labeled company. Under that, you've got a node labeled web. So the domain name of the pri node would be pri dot, the name of the company node would, of course, be company dot pri dot, and the domain name of the web node underneath the company node would be web dot company dot pri dot. Okay this entire tree structure is called the domain name space. Every node connected to the root and the root itself is part of the domain name space. And this one looks pretty manageable. It's small and you could easily store this on a single server. But what if this thing were to grow to say billions of nodes? Storing it on a single server just is not going to cut it. And if it were to grow to billions of nodes, that's an awful lot of management overhead for one team to handle, let alone one person. Most likely such a large tree would need to be managed by different people. So having this domain name space under the control of a single entity also is not going to work. To put it concisely, DNS needs to be scalable.

Scaling DNS
At the outset, I said that DNS is a database. To put a finer point on it, DNS is a database for storing resource records, but it's not just any old database. DNS is scalable in two respects, first it's scalable in that it's able to store an increasing and ever changing set of nodes, and second it's scalable in the sense that it's not necessarily controlled by a single person or group. That way the management overhead of a very large name space doesn't have to fall on a single entity. DNS accomplishes this by dividing up the name space. First, portions of the name space, that is to say domain names, are delegated to different people or groups so that they can modify only their portion and nobody else's. And by modify I mean add and remove child domains in resource records. It's then the responsibility of those people to provide name servers to hold their delegated portion of the name space. The net effect is that the entire name space is distributed across different name servers such that no single server has to store the entire tree, each server stores only a subset of the tree. To illustrate this with our sample name space, we break the tree up into pieces and store these pieces on different name servers, each name server holds one or more domain names and all of the resource records associated with it. In this example we store the root domain name on the name server named NS1. Once again, the root node has a null zero length label, which we represent as just the dot. The com domain is stored on NS2, and both the example. com and web. example. com domains are stored on NS3. The pri domain is stored on NS4 and the company. pri domain and its child domain, web. company. pri, are stored on NS5. In DNS terminology, each of these pieces is called a zone. The way you identify a zone is by the domain name closest to the root, which we call the origin or apex of the zone. For instance, you would say NS3 holds the zone named example. com because the example. com domain is closest to the root. Again, it's the origin or the apex because it's where the zone begins. Now by the way, the name server names here, NS1, NS2, NS3 and so on, are just placeholders for the real name server domain names, which are usually much longer, as we'll see in a moment. Now all this raises an obvious question, how exactly is all this zone information stored? What does it look like? Well again, we've decided to split the tree according to various zones. NS1 contains the root node and nothing else. Notice that I've added the key word origin here to indicate the zone name. This helps to distinguish it from individual domain names within the zone. Hint, NS1 hosts the root zone, NS2 contains the com domain name and nothing else, thus NS2 contains the com zone. NS3 contains the example. com and web. exmaple. com domains and nothing else, and as we said a moment again, NS3 contains the example. com zone. And so on for the pri and company. pri zones. We've split the tree up across different name servers so that each name server holds a different zone, but no single name server contains the whole tree. To use the DNS term, each name server is authoritative for a zone. The root word of authoritative is author and that's appropriate here. The name server is the author of the zone, it's where all the information about that zone is stored. Okay, let's create a resource record for the domain name web. example. com. This resource record will describe an IP address resource. Now web. example. com falls within the example. com zone and NS3 is authoritative for that zone, we will create this record on NS3. We'll represent this record by specifying the domain name, web. example. com, followed by the type of resource we're storing, which is an IP address. The letter A standing for address. We'll then follow that with the IP address itself, which is 1. 2. 3. 4. So okay, as it stands right now, we've got a domain name space spread across different name servers, and we've got one resource record. The next question is, how does a client retrieve this resource record? That's what we're going to tackle next.

Querying DNS
We broke the domain name space into pieces and we spread it across different name servers to make DNS scalable. But that scalability comes at a cost. One of which is increased complexity. Take a look at the diagram again. Now imagine a client who has no knowledge of this name space, and when I use the term client, understand that I'm not talking about a user sitting at home surfing the internet, maybe eating potato chips, a client in this case is a software program that retrieves information from DNS by querying one or more name servers. Now here's the question, suppose the client wants to find the IP address of web. exmaple. com. How does it know which name server to query? The answer is, it doesn't. The client has no idea that NS3 has any information about web. example. com. Now you might think, well the client can just somehow obtain a copy of the entire name space, which is quite small, but imagine this name space having billions of nodes and getting updated and changed every second. Not only that, the name space is spread across different servers so compiling a copy of the whole tree would require querying a server for every zone. A client maintaining its own copy of the entire structure is just not feasible. So we need a different solution. We need a way for the client to be able to find out which name server has information about the specific domain name that the client is interested in. And here's how we do that. Let's start with the root. The root name server contains pointers to the name server that hold it's child zones, which in this case are com and pri. NS1 contains a name server resource record that says the com zone lives on NS2. NS1 also contains another record that says the pri zone lives on NS4. Okay, now let's take a look at NS2. NS2, again, holds information about the com zone. It also contains a name server record that says the example. com zone lives on NS3. And if we look at NS3, we can see that it indeed has information about web. example. com. Now by the way, notice that I have the name servers listed in lowercase, whereas in the proceeding diagram they were listed in uppercase. I do this to highlight the fact that DNS is case insensitive, and also to distinguish the name server resource type, which is NS, from the name server resource data, NS1, NS2, NS3, and so on. Okay, let's take a look at another example. What about web. company. pri? Well NS4 holds the pri zone and it has a name server record pointing to NS5 for the company. pri zone. And web. company. pri can be found on NS5. So now we have a hierarchical relationship between the name server themselves that mirrors the domain name hierarchy, but notice what we've just accomplished here. We've just solved the client's dilemma. We walked through the exact same process a client would have to go through in order to find out the IP address of web. example. com and where did we start? We started at the root. Now using this process, the client can retrieve information about any domain name by initially querying the name server that holds the root zone, that's NS1. In DNS parlance, NS1 is the root name server. Now just to make sure we're on the same page, let's walk through the process again. The client begins by querying NS1 and asking for the A record for web. example. com. NS1 does not have any information about web. example. com or even example. com, but it does have a name server record stating that the com zone is stored on NS2. NS1 sends a response to the client containing that name server record. Essentially NS1 says to the client, I don't have an A record for the domain name web. example. com, but NS2 does hold the com zone, so go ask NS2. The client then queries NS2. NS2 looks at its database and sees that the example. com zone is stored on NS3. So it sends the client that name server record that says NS3 holds the example. com zone, so go ask NS3. The client then begrudgingly asks NS3 for the A record for web. example. com. NS3 looks at is database and says, ah-ha, I do have an A record for that domain, here you go, and it sends that record, which contains the resource record data, that is the IP address 1. 2. 3. 4. And that's it. This process here is called recursion. The clients keeps following this trail of name servers until it either locates the record it's looking for or it gets a response indicating that the record doesn't exist. How does the client know to start with NS1? Well it has to be common knowledge, that's really the only way this system is going to be useful. Every client who wants to pull data from this domain name space must know that NS1 is the root name server, and that means that whoever controls the root name server has quite a lot of power over this entire domain name system. And this is where this rather lengthy conceptual exercise meets the real world. In the next clip, we're going to look at how the domain name space actually gets built and how it's implemented on the internet so that everyone can use it.

The Internet Domain Name System
When it comes to the internet, everyone needs to be able to access the same domain name space, we'll call this the internet domain name space, or just the public name space for short. That means every client needs to know which name server is hosting the root zone of the public name space. Let's take a look at a very simplified version of what the actual public name space looks like. At the top, you've got the root zone, which is stored on the server a. root-servers. net. This, again, is called the root server, and it's controlled by the internet assigned numbers authority. Underneath that, you have three zones which should look familiar, com, net, and org. These are often called top level domains, or TLDs. Right now there are over 1500 top level domains on the internet, but I'm just showing three here to keep it simple. Each of these is a public zone, it's public because it's available on the public internet, and of course the word zone implies that it's under the control of a single entity. Here each of these public zones or top level domains is under the control of a registry operator. The registry operator for the com and net zones is Verisign, their name server is a. gtld-servers. net. GTLD standing for generic top level domain. The operator for the org zone is the called the public internet registry. And yes, that's actually the name of the organization. And their name server is a0. org. afilias-nst. info. That's quite a long name. Now please direct your attention back to the com zone. Just one level under the com zone, there are over 133 million other domain names, one of which is my humble domain name benpiper. com. The zone for benpiper. com is stored on ns-517. awsdns. 00. net, another lengthy name there. This is one of Amazon's route 53 name servers. Yes, after all that we're finally getting around to talking about route 53. We took the long route to get here because I want you to have a crystal clear and holistic picture of how route 53 fits into the domain name system. Now recall that exercise we went through earlier where a hypothetical client walked up the domain name space tree, starting with the root, in order to retrieve a particular resource record. We're going to do a similar exercise again, but this time we're going to query the real internet domain name space and we're going to do so at the command line. In this demo, I'm going to introduce you to a utility you may have even used before, it's called nslookup, short for name server lookup, and it has one job, to query a name server for a resource record. The goal here is to retrieve an A resource record for benpiper. com by starting with the root server. Remember that the A resource type is for an IP address. Let's jump over to the command line. First I'll query the root server to see if it knows which name server hosts the benpiper. com zone. So we'll do nslookup -type=ns, for name server, benpiper. com is the domain name and a. root-servers. net is the name server that I'm querying. Hit Enter here and it spits back a lot of data, but the data we're interested in starts with com. This refers to the com zone. Notice that it gives us a list of names ending in gtld-servers. net. These servers are Verisign's name servers that hold information for the com zone. Recall earlier, I mentioned one of these, a. gtld-servers. net. Each of these 13 name servers holds a copy of the com zone. In fact, the DNS specification requires that a zone be stored on at least two name servers for redundancy. In this case there are 13. Hint, we could query any of these, but just to be consistent, we'll query the A server. So we'll do nslookup -type=ns benpiper. com a. gtld-servers. net. And once again, just to reiterate that -type=ns causes nslookup to ask for a name server resource record. We'll hit Enter here. Now here it gives us four name server entries for the benpiper. com zone. These all contain some variation of awsdns- and a number. These are the Route 53 name servers that are hosting the benpiper. com public zone. Just as with Verisign servers, each of these Route 53 servers contains a copy of the zone. So let's go ahead and query one of these. Nslookup -type=ns benpiper. com, and then we'll do ns-517. awsdns-00. net. Notice they return the exact same name server records. Now this is a clue that these name servers have complete information for the benpiper. com zone. Let's do another query against one of these servers, only this time I don't want to query for a name server record, I want to query for an IP address. So I'll change the type of the query to a for IP address, nslookup -type=a benpiper. com and then ns-517. awsdns-00. net. And finally, we get the IP address for benpiper. com. Pretty cool. And that, my friends, gives us all the context we need to start learning, configuring, and otherwise diving deep into Route 53. Let me close this out with a question to ponder, how do Verisign's name servers know that those particular Amazon Route 53 servers had information on the benpiper. com zone? Did Amazon tell them? Did I tell them? Or did some third party tell them? Well that's the question we're going to answer after we walk through the lab set up for this course. That's coming up next.

Course Overview
In this module I've introduced just enough DNS terminology and background to get us started. Now let's briefly overview what we'll be covering in this course when it comes to Route 53. We'll start off simple by creating simple resource records. A simple resource record just points to one, and only one, resource. Again, a resource is generally going to be an IP address endpoint. It could be an instance, a load balancer, an S3 bucket or anything that has an IP address. These resource records will live inside of a public hosted zone, which will also create, and which, as I said earlier, is just a zone that's available on the public internet. Next, we'll configure health checks and failover records. Together these allow you to direct traffic away from failed instances and towards healthy instances without having to depend on a load balancer. After that, you'll learn how to use weighted records to control how much traffic each resource receives. This is useful when you want to release a new feature or bug fix, but you want only a small percentage of users to actually access the instance with the new release, that way if anything goes terribly wrong, it impacts only say 5 or 10% of users, rather than 50 or 80%. Following that, you'll learn how to configure geolocation and latency-based routing policies. The goal of these is to direct users to the resource that's going to give them the best performance. However, the goal and the reality don't always match up. And you can end up with some pretty surprising results, as we will see later on. As a little teaser, geolocation policies do not direct users to the resource closest to them, which leads us to the next topic, traffic flow policies. The big benefit of these is that they allow you to create what are called geoproximity records. These do allow you to direct users to the geographically closest resource. After that, we'll configure load balancing with multivalue answer routing policies. This lets you do load balancing at the DNS level without having to use a load balancer. Following that, we'll dig into private hosted zones, which in contrast to public hosted zones, are not available to the public internet, but are instead only available to instances within your VPCs. Last, but certainly not least, we'll close out the course with a look at how to transfer an existing domain name from a third party registrar to Route 53.

Summary
In this module we looked at how the domain name system works at a high level and how the internet domain name space is structured and allocated. Coming into this course, you would probably already familiar with some of the terms and concepts we covered. My goal with this module was help to put everything into context so that you can see not only how DNS works, but why it's designed the way it is. Having a holistic, bird's eye view of DNS is going to be extremely helpful to you when configuring Route 53. The primary, but certainly not the only purpose of DNS, is to map domain names to IP addresses. Together, all of the domain names on the internet compose what's called the domain name space. The domain name space is organized in a tree structure, which is broken up into zones. A zone consists of one or more domain names and is stored on at least two name servers, along with the resource records for the zone. In the examples, I showed only one name server for simplicity. Two name servers aren't required for DNS to actually function, but it is part of the DNS specification. The resource records are the data structures that consist of a domain name; such as example. com; resource type, such as a for IP address; and resource data, which would be the IP address itself. As we saw, there are other resource types, such as the name server type. Well I hope you love DNS and AWS as much as I do because in the next module we're going to set up our AWS environment and get everything prepped and ready to start configuring Route 53. See you there.

Lab Setup
Lab Considerations
In this module we're going to set up the lab environment for the course. I've designed this lab environment so that it can cover almost any use case for Route 53. That means that regardless of how you plan to use Route 53, this environment is going to provide you a great place to practice. Now when it comes to the labs, we'll be working with a public domain name, obviously the domain name I use will be different than the one you use. So now's a good time to decide which domain name you want to use in the labs. This is the first step. There are two possibilities. Either you have an existing domain name already registered, or you don't and you want to get one. If you don't have a domain name, that's perfectly fine, don't worry, I'll show you how to get one in the next module. In fact, I'll cover both scenarios in the next module. But for now, please go ahead and decide whether you want to use an existing domain name or a new one, that will allow you to follow along with the labs uninterrupted. As you're making that decision, please consider the following. If you're going to use an existing domain name with this course, please make sure it's not important. You will be making changes to the domain name, and if you're using it for something important, those changes will have undesirable long term consequences. Now I don't mean that to sound dramatic, when I say long term, I'm talking at most 48 hours. If you use your domain name for a test application, that gets used every once in a while, a 48 hour outage may be fine. If it's a production application that people use every day, well a 48 hour outage may be a resume generating event. It's the kind of thing that can make you lose your job. Again, not trying to sound dramatic here, but if you're thinking of migrating a production domain name to Route 53 as you follow along with this course, please don't, please use a practice domain that's designed for testing or development. And if you don't have one, again, you'll have the opportunity to create one in the next module. We're going to start out with two regions. If you're going to follow along with the labs, you can choose any regions you'd like, but I'm going to use us-east-1, which is Northern Virginia, and us-west-1, which is in Northern California. In the Virginia, or east region, we'll have two instances, each with its own elastic IP address. These instances are going to run a very simple web application that connects to a database server on another instance in the same region, the database server itself will also have an elastic IP address. In the California, or west region, we'll have two instances running the same web application. These servers also connect to the database server in the east region. Just to be clear, this diagram is our starting point, it's not the whole story, and we are going to add to it later. But in this module, what you see here is what we're going to set up. Now when it comes to setting up your AWS environment, you have two options, you can either do so manually or you can use a PowerShell script that I've created for you. Before you decide, please consider the following, recall that I said earlier you need a level of comfort with the command line to get the most out of this course. Because you're going to be using the command line a lot anyway, I strongly recommend using the PowerShell option for setting up your lab. Here's why. PowerShell is available for Linux, Mac OS, and of course Windows. Microsoft maintains a GitHub repository with links to the latest releases, so if you don't already have PowerShell, just go to GitHub. com/PowerShell/PowerShell to download your free copy. To make life easier, in addition to the lab set up script, I've also created some scripts to help you test your Route 53 configurations. These are not required, but I highly recommend then. Also, if you plan to use multiple domain names with Route 53, there is one feature that you may be interested in, which is not available via the Route 53 console as of this record. It is available via the Route 53 API, which of course, you can access using PowerShell. So what I'm saying is, please strongly consider PowerShell for this course.

Manual Lab Setup
Let's start with the manual setup. If you're not sure whether you want to use PowerShell, this clip may help you decide. Let's get to it. First, you'll need to create a VPC with a CIDR of 172. 3. 0. 0/16. I'm going to create this VPC in the us-east-1 region, but you can use a region of your choice. Within the VPC, you'll need two subnets, one with a prefix of 172. 3. 0. 0/24 and another with the prefix of 172. 3. 1. 0/24. Make sure you place the subnets in different availability zones according to the naming convention. In a different region, you'll need another VPC with a CIDR of 172. 9. 0. 0/16. Therein, you'll need two subnets, one with an IP prefix of 172. 9. 0. 0/24 and another with a prefix of 172. 9. 1. 0/24. And for me, this VPC is going to be in the us-west-1 region. Be sure to enable DNS hostnames in both VPCs. You can do this under the VPC action menu in the web console. You'll also need to create an internet gateway for each VPC. I'm going to name this r53-lab-igw for both VPCs. Next, for each VPC, you'll create a route table called r53-lab-right and you'll associate it with all of the subnets in the VPC. Within the route table, you'll create a default route with the internet gateway as the target. We're going to have one security group, the r53-lab-sg group will allow all HTTP traffic from any source. You also want to allow SSH access from your particular IP address. All of the instances are going to use the same Amazon machine image, which you can find by searching for this ridiculously long name. Any image that begins with this string should work. Notice that the asterisk at the end of it is just a wild card and not actually part of the name. Of course by the time you watch this there may be a later release, but you'll want to make sure it has the ecs-hvm in the name, which you can see I have in bold here. Now these are the ami IDs I'm going to be using. So, if you're going to build your own AWS environment using the same regions, you can just search by these particular ami IDs. As I mentioned already, we're going to have five instances. Three instances, web1-east, web2-east, and db-east, are going to be in one region. The other two, web1-west and web2-west, are going to be in a different region. As for the instance type, I'm going to be using t2 nano for all of these, but if you want to use something bigger, you're more than welcome to do that. Alright that's it for the manual set up.

Configuring PowerShell and the AWS Tools for PowerShell
In this clip we're going to install and configure the AWS tools for PowerShell. As I mentioned before, you need to complete this step if you want to use my lab setup script to automatically build your lab, or if you want to use any of my testing scripts, or if you're going to be using multiple domain names with Route 53. Those scripts are available in the course exercise files, as well as on my GitHub repository at the URL you see here. With that, please go ahead and open up a PowerShell prompt with administrative or root credentials and let's get started. Here I am at an administrative PowerShell prompt. The first thing we're going to do is grab the course exercise files. You can download these either from the Pluralsight website or from my GitHub account. I'm going to grab the course exercise files from GitHub by typing git clone https://github. com/benpiper/aws-powershell and hit Enter. Now if you don't use Git or you don't want to use Git, you can actually just browse to that URL and download the exercise files as a zip archive. Once you have the files, change directories to the aws-powershell directory and here we're going to run. space. /install-awspowershell. ps1, which will install and load the AWS tools for PowerShell. This process takes about a minute or so, so go ahead and hit Enter here and then pause the video if you need to and resume it when it's complete. Once the install is done, you should see the version number, which in my case is 3. 3. 253. 0. Next, we're going to go to the Route 53 directory. We'll do cd route53. And we're going to edit a file called _credentails. ps1. Here you're going to enter your AWS access key and secret key that you're going to use for the lab. Make sure that the iam user you specify has full administrator permissions. I don't want to reveal my credentials here, so I'm going to enter them behind the scenes, but once you've entered your credentials, save the file and then close it. Once you've done that, go ahead and rename the file to credentials. ps1 without the underscore character. So to do that, I'll just do mv _credentails. ps1 and then rename that to credentials. ps1 again without the underscore character. Once you've done that, go ahead and run. space. /test-connection. ps1 and hit Enter, and if you see connectivity to AWS established, then you have successfully configured your credentials and you're good to go.

Setting up the AWS Environment Using PowerShell
In this clip we're going to have the PowerShell script, which I've provided in the course exercise files, set up the AWS lab environment. But first, you're going to make a few changes to the script to customize it for your particular setup. Let's jump back over to PowerShell. First, go ahead and open the file lab-setup. ps1. Scroll down to line 10 and notice the four variables here. These are where you're going to specify the two AWS regions you want to use, as well as the ami IDs for your instances. For the regions, I'm going to use us-east-1, which is in Virginia, and us-west-1, which is in California. You can use whichever regions you'd like, and keep in mind that you don't have to choose multiple regions, you can just specify the same region for both if you want. Also, remember that ami IDs are region specific, so if you choose different regions, you need to go and search each region for the specific AMIs you want. To make it easier to search for those, I have provided the names of the images here in the comments. If you want to search for an image directly from PowerShell, go down to line 17 and change the region to whichever region you want to search in, for example, EU-west-2, which is in London. Now I'm going to go ahead and run the command here on line 16 and then the one on line 17, and we get only 1 image. So if you want to use the London region, again, just for example, you can plug this image ID into the script, change the region, and save the script. I'm going to go ahead and comment out line 17 so that it doesn't run again when we run the script. Moving down a bit, on line 20, change the myIP variable to cover the IP address range from which you want to allow secure shell access to your instances. Okay, now look down at lines 23 and 24. This is where you need to specify the key pairs you want to use to SSH into your instances. Remember that these are region specific, so you may have these names differently. In my case, the keys in both regions are named the same. If you go down to line 27, you can view your existing key pair names by running the Get-EC2KeyPair command against each region, like so. First I'm going to run it against the northern Virginia region, and there you can see my key pair name ccnetkeypair, along with the fingerprint. I'll run the command again against the northern California region, and there you can see I've got a key pair with the same name, but a different fingerprint. Now if you don't get any results for a given region, then that means you don't have a key pair configured and you most definitely should take care of that before continuing. Alright, one more thing and then we're going to run this script and let it build out our lab environment. Please scroll down to line 31. Here you may change the instance type to whatever suites your fancy. I'm going to use t2. nano, which is fine for our lab environment. If you're using the AWS free tier, you may want to change this to t2. micro, so that you can take advantage of that special introductory pricing that Amazon offers to new customers. Once you've customized the script and saved it, I'm going to go ahead and close it here and then save it, and then I'm going to clear the screen. Once you've done that, go ahead and run it by typing. space. /lab-setup. ps1 and hit Enter. Now you may see some errors stating that certain resources don't exist. These errors are related to tagging resources, and you can safely ignore those because they don't impact the functionality of the lab environment. Once it drops you back to the PowerShell prompt, you should be able to go into the web console and verify that everything looks the way it's supposed to. However, to make this easier, I've created another script which will give you the elastic IP addresses of each of your instances. And to run that script, just enter. space. /get-instance-eip. ps1, and what it's going to do is it's going to go out and grab the name tags and public IP addresses of every instance in every AWS region and display them on screen. And here they are. Now you'll notice that at the beginning I have five instances with no IP addresses. These are actually terminated instances that I created a little bit earlier and AWS has simply not cleared them out of its system yet. You may see a similar thing if you have terminated instances in your environment. Now notice that in addition to displaying the plain public IP addresses for each instance, the script also shows a URL. We're going to use these URLs in a moment to test connectivity to the web application on each instance, but before we can do that, we need to get the web application up and running. And that's what we're going to do right now.

Setting up the Web Servers
In this clip, we'll configure the web servers, which we're going to use to validate our Route 53 configurations throughout the course. This part is really easy because I've already configured the web servers for you, you just have to run one command on each instance. Go ahead and SSH into each of the web server instances, but don't SSH into the database instance just yet. We're going to get to that one later. Once you're logged into all the web instances, jump over to the command prompt on web1-east. Here we are on web1-east and the command we're going to issue is this: sudo docker run --rm -p 80:80 benpiper/r53-ec2-web. Now this command will instruct Docker to go out and fetch a preconfigured web application, which I've created specifically for this course, and it will make it accessible via TCP port 80. Once you've got the command typed in, hit Enter and it'll take a couple minutes for everything to download and start. So while you're waiting, go ahead and issue the exact same command on the rest of the web instances. I'm going to do this behind the scenes, so please pause the video, issue the same command on the rest of the web instances, and when you're done, resume the video and we'll verify that everything works. Once the web server is up and running, you should see a message saying ready to handle connections. If you see that on each web instance, then you should be able to browse to each instance's elastic IP address. To do that, let's jump back over to PowerShell. Once again, we have the list of public IP addresses for each of our instances. If you're using Visual Studio code, you can hover your mouse cursor over any of these URLs and it gives you the option to browse to it. Let's start by browsing to the public IP address for web1-east. I'll hold down Control and click and then I'll jump over to Chrome and voila, here is the web application, which we're going to use to test our Route 53 configurations. Now as you can see, there's a lot of info here. We're going to briefly walk through this line by line, but I'm not going to get into a lot of detail just yet because right now all we're concerned about is whether the lab environment is set up correctly. Let's start at the top. The local domain name is the internal name that AWS assigns to the instance. You'll sometimes see this called the host name. In fact, that's exactly how AWS refers to it. The local domain name is unique to the VPC and it's not resolvable from outside of the VPC at all. Inside the VPC, this resolves to the primary IP address of the instance's internal IP address, which in this case is 172. 3. 0. 10. Next, we've got the public domain name of the instance. This one is resolvable from the public internet and it resolves to the public IP address, which in this case is just an elastic IP. The next line shows the availability zone, us-east-1a, which is, of course, in the northern Virginia region. Now the purpose of these first four lines is to make it easy to uniquely identify the instance. Right now we're browsing to this particular instance by its unique public IP address, so we know exactly which instance we're connecting to, but later on we're going to be browsing to a domain name, and so we'll need a way to determine which specific instance we'll be hitting at any given time. Moving on, the client IP shows my public IP address and the client domain name is the domain name that my internet service provider has associated with my IP address using what's called a pointer record. It's possible, although unlikely, that you won't see a client domain name at all, and if you don't, that's okay, it's not necessary in order for you to follow along with the course. On the next line, we've got the host header. This is an HTTP header that the web browser passes to the web server and it contains exactly what you see there in the address bar, which is just the public IP address. Now even though you can't see this in the address bar, there is an implied HTTP:// before the IP address, that's the URI prefix and it is not part of the host header. Later on, once we configure Route 53, this host header is going to actually contain a domain name instead of an IP address. Last, but not least, is the hit counter. This just displays the number of HTTP requests to this individual instance, so if you refresh the page, I'll hit F5 here, you can see that it increments.

Summary
Okay, that's it for the lab setup. If you haven't completed the setup, please go ahead and do so before continuing with the course. Again, I encourage you to use PowerShell for this course because not only does it make the lab setup easier, but you're going to be doing a lot of things at the command line anyway, so you might as well take advantage of some of the scripts I've created to help you test out your Route 53 configurations. Next up, we're going to get to the meat of the course, we're going to start actually configuring Route 53. See you there.

Creating Public Hosted Zones and Simple Records
Module Introduction
Welcome back. In this module you're going to learn how to configure Route 53 to host DNS services for your domain name. Now recall from earlier, I said that you need to decide whether you want to use an existing domain name, which you've already registered, or if you want to register a new domain name using Route 53. Regardless of which of these options you've chosen, please watch this module from beginning to end because I'm going to cover both. Here's the high level overview of what you'll learn in this module. First, you'll learn how the domain registration process works, and specifically how a registry operator knows which name servers are authoritative for a domain. Next, you'll learn how to use an existing domain name with Route 53, and finally, you'll learn how to register a new domain name with Route 53. This all sounds pretty simple and straightforward, but as you're going to see, there are a lot of details lurking beneath the surface, and, hint, a lot we have to cover. So let's get started.

Understanding the Domain Registration Process
Whether you've already registered your domain name or you have yet to register it with Route 53, it's vitally important to understand what happens when and after you register a domain name. To illustrate the domain registration process at a high level, let's consider what happened when I registered my domain name, benpiper. com. Recall from earlier in the course that Verisign holds the top level domain, or TLD, for the com zone. This is where all of the. coms are stored, such as Pluralsight. com. Verisign is the registry operator for this zone and a. gtld-servers. net is the primary name server for the com zone. In order to register my domain name, I did not go to Verisign directly, instead I went to a registrar. A registrar is an intermediary that sits between you and the registry operator of the TLD. I told the registrar, I want the domain name benpiper. com. They checked with Verisign to see if it was available, which it was, and I paid my registration fee to the registrar. At that time, the registrar then told Verisign the name servers for benpiper. com should be dns1 and dns2. registrar-servers. com. Now stick with me because this is going to get a little confusing. Verisign then created two name server resource records on their name server, which hosts the com zone, again, that's the a. gtld-servers. net name server. Those name server records specify that dns1 and dsn2. registrar-servers. com hold the benpiper. com zone. Now at this point, you may be scratching your head and thinking, okay where did those name servers come from? Well, those DNS servers are owned and controlled by the registrar. Again, I told you this would get confusing. So let's look at this a different way. When I registered my domain name, Verisign, which, again, is the registry operator for the com zone, added two name server resource records on their name server. Each of those resource records contains the domain name, benpiper. com, a resource type, DNS for name server, and the resource data, which is the name of the server holding the benpiper. com zone. Each of those name servers, dns1 and dn2, which, again, are the registrars name servers, those servers contain information for the benpiper. com zone. They are authoritative, if you remember the term, because they contain complete information for the zone. Now, why am I telling you all this? Why do you need to know this? Well in my experience, this whole process is a major point of confusion, and understandably so, in large part because almost all of it happens behind the scenes. The sooner we pull back the curtain, so to speak, the less likely you are to get confused by all this when we revisit this process later on in the module. Registering a domain name is all about getting the top level domain registry to create name server records for your domain that point to your name servers. When you register a domain name, the registrar provides their own list of name servers to the registry operator. Typically, these are going to be the registrar's own DNS servers. To use Route 53, however, we need to get the registrar to update the registry operator with the Route 53 name servers and that raises the question, what are those name servers? How do we find out? That's what we're going to cover in a moment. But first, a brief overview is in order. To put into perspective this whole relationship between the registrar and the name servers, it may help to understand that there are only four possible states of affairs, which can be represented in this four quadrant table. At the bottom right quadrant, you have an existing domain name registered with a third party registrar, and you're using some third party DNS service. In this module, I'm going to show you how to move from this quadrant to the bottom left quadrant wherein you are still using a third party registrar, but now you're using Route 53 for your DNS services. Another possibility is that you have no domain name and you simply register a new domain name with Route 53. This will place you in the top left quadrant with Route 53 being both your registrar and your DNS service provider. There's also another possibility, which I won't cover in this module, but later on in the course, and it's this, you have an existing domain name with a third party registrar and you're using a third party DNS service. Again, we're back in the bottom right quadrant. You then transfer your domain name registration to Route 53, which places you in the top left quadrant. See how that works? If you're not sure how to proceed, just look at this quadrant and find out where you are right now, then just figure out which quadrant you want to move to and that should give you a good idea how to proceed. By the way, the top right quadrant doesn't come into play at all in this course because generally if you register your domain name with Route 53, you're also going to use it for your DNS. Technically you don't have to, but if you're not going to use Route 53 for your DNS services, then there's really no reason to watch this course.

Using an Existing Domain Name
As I said, in order to use an existing domain name with Route 53, you must update the registrar with the correct Route 53 name servers, but before you can do that, you have to know what those name servers are. There are two ways to go about getting name servers for your domain name. The first way is to create a public hosted zone. This will give you 4 Route 53 name servers and store the zone on those servers. The second way is to create a reusable delegation set. This will give you 4 Route 53 name servers and nothing else. It will not create a hosted zone and it will not store any zone information on the servers. You must manually associate this delegation set with a zone yourself. One thing to keep in mind is that you must use the name servers AWS assigns to you. You can't just take the ones I'm using for my domain name, for example. The reason is that when you create a zone, that zone gets store only on the four name servers AWS gives you. Now I realize that's hard to visualize, so let's jump straight into the demos so you can see all of this for yourself. Let's go ahead and start by creating a public hosted zone. Before we do anything that's going to actually affect your existing domain name, we're going to practice. It's important that you get comfortable with a Route 53 console and that we reinforce and clarify some of that DNS terminology we covered earlier. In this demo, we're going to practice creating and deleting public hosted zones. Let's jump over to the Route 53 dashboard. Here we are at the Route 53 dashboard, and we're going to start off by going to hosted zones on the left side menu. From here we're going to click one of these Create Hosted Zone buttons. Now once I click it, you'll notice it doesn't really do anything, it just tells me you have no hosted zones. This is actually a quirk with the web console, so just go ahead and click the Create Hosted Zone button again, and now here, finally, we have the chance to create our hosted zone. Under domain name, I'm going to put benpiper. host. I'm using the domain name benpiper. host because this is actually the domain name which I've registered with my third party registrar, and I'm going to use it throughout the course for the demonstrations. You, however, can put whatever you want to here. You can use your own domain name or you can actually just make something up. What you enter here will have no impact whatsoever on any existing domain names. Under the comment here, I'm just going to go ahead and put public, and for the type, we're going to stick with public hosted zone. We'll click the Create button down at the bottom right. And it immediately takes us to the new hosted zone. We'll go ahead and scroll to the left here so we can see the records better, and we'll go ahead and click on this first record set here. Notice that we have four name server resource records here. These name servers are each holding a copy of the benpiper. host zone. In Route 53, this actually looks like a single resource record, but it's actually 4 separate name server records, but it's consolidated into what's called a resource record set. In fact, even if you have a single resource record, Route 53 still calls this a resource record set. Technically it's a set of one, so for all practical purposes, a resource record and resource record set are the same thing. Now let's go ahead and click on the SOA record set. AWS has also created another record with a type of SOA, which stands for start of authority. We'll talk about the SOA record in more detail later, but notice that in the value, it lists one of the name servers which we saw in the name server records, which is ns-364. awsdns-45. com. This is the primary name server for the zone. Now keep this name server in mind and let's click on the hosted zones link on the left. We're going to create another hosted zone and we're going to give it the same name as the one we just created, so I'll click Create Hosted Zone, and under the domain name I'll put benpiper. host and under comment I'll just put duplicate. We'll, of course, leave this as a public hosted zone type and click Create. It creates the new hosted zone, no problem, even though it has the exact same name as the one we just created. So what happened here? Did it overwrite the original zone? No. If we scroll to the left here, notice that the name servers are different. AWS created a new zone on different name servers. Now look at the SOA record. It shows ns-743. awsdns-28. net. That's the primary name server for this zone. That's different than the one we saw before. So the point here is that the zones you create in Route 53 have no relationship whatsoever to any internet domain name. Right now, these zones are nothing more than data stored on Route 53's DNS servers. Now let's go back to the hosted zone list, and look at that, we have two public hosted zones with the same domain name. And by the way, because these are separate zones, you will be charged for each of them after 12 hours. If you delete them before 12 hours, you will not be charged. Again, these are just zones in our 53's DNS, nobody else on the internet knows about these zones. Now normally you wouldn't create two public hosted zones with the same name, but I did it to illustrate that a zone and an internet domain name are not the same thing. Simply creating a zone in Route 53 is not the same as registering it with a registrar, and it does not have any effect outside of Route 53. To illustrate this point further, let's create another hosted zone. We'll name this one Pluralsight. com and under comment we'll put not the real thing, and then we'll create this one. Scroll to the left here, and notice that the name servers and SOA record are different. Every time we create zone, we get different name servers. Also, notice that there are no other records here. If we were looking at the real DNS records for Pluralsight. com, we would see at least a dozen records here, but we don't, so even though this zone has the domain name, Pluralsight. com, it clearly has nothing to do with the internet domain name, Pluralsight. com. The two are completely separate. Now let's jump back to hosted zones. And let's go ahead and delete the Pluralsight. com zone, we'll do that by clicking on the radial button to the left of it, and then clicking Delete Hosted Zone. Are we sure we want to delete it? We're sure, it's not going to actually effect anything important, click Confirm, and it's gone. Now click on the line of the first zone we created, don't click on the domain name itself, but just click on the line. Now as I mentioned before, every time you create a zone, Route 53 assigns you a different set of name servers. Notice that underneath the list of name servers it says, "Before DNS will start to route queries for this domain, to Route 53 name servers, you must update the name server records with the registrar for the domain. Now the internet domain name, benpiper. host, is registered with a third party registrar, it's not registered with Route 53. So this means if I want to actually use this zone, I have to take these name servers and give them to the registrar. Not a big deal, right? Well for just one domain name, no it's not a big deal. But remember that every time we create a new zone, we get different name servers. But suppose you have 20 domain names and you want to use Route 53 for all of them. You'd have to create a zone for each domain, make a note of the name servers, which again, are different for each zone, and then update the registrar with those servers. Now can you imagine how long that would take? No thank you. Okay, fortunately there's another option. We can get Route 53 to assign the same set of name servers every time we create a zone, but there's one caveat. We cannot do it from the web console. We're going to have to use the API and that means using PowerShell. So that's what we're going to do next. Before we jump into that, let's go ahead and delete these two zones. I'll go ahead and click Delete Hosted Zone here and confirm. That leaves us with one, the duplicate, we'll delete that one. It's gone, and now we have no hosted zones.

Creating Reusable Delegation Sets
In this clip, I'll show you how to create a reusable delegation set. A reusable delegation set is simply a set of Route 53 name servers that you can associate with up to 100 hosted zones. This is very useful if you've got multiple domain names, but don't want to deal with the confusion and hassle of having a different set of name servers for each hosted zone. In this demo, we're going to create a reusable delegation set using PowerShell. After that, we'll create a public hosted zone, again, using PowerShell, and we'll associate that delegation set with the zone. Please go ahead and open up, in your favorite editor, the file reusable-delegation-set. ps1. Take a look down at line 7. The command to create a delegation set is New-R53ReusableDelegationSet. Now the CallerReference parameter here is not specific to Route 53, but it must specify a unique string. The Get-Random cmdlt there just generates a random number. The purpose of the CallerReference is to uniquely identify the request to create a delegation set. This lets us retry the request, if it fails, which it should not. I've actually never had it fail. So let's go ahead and run this. I'll hit F8 to run it. And now let's go ahead and jump down to line 8 and we'll run Get-R53ReusableDelegationSetList. AWS returns the identification of the delegation set, the CallerReference, which is just that random number that PowerShell generated, and the thing we're most interested in, the list of name servers. Now let's take a look at these in a cleaner format. Please go down to line 11 and run that. And there we go. There's our list of name servers. Now we can now take this list of name servers and associate it with up to 100 hosted zones. We're dealing with just one domain name for now, so next we're going to create just one public hosted zone, but this time we're going to associate this delegation set with that zone. And here's how we'll do it. Scroll down to line 14, right here. Now the first thing we're going to do is grab the DelegationSet. Id and store it in a variable. Now jump down to line 17, here we set the zonename variable equal to the name of the zone that we want to create, which in my case is benpiper. host. Now be sure to change this to reflect your domain name. Notice also that I have a trailing dot at the end, so it reads benpiper. host dot. The trailing dot at the end is actually optional, but I do like to put it when dealing with a lesser known top level domain like. host, just so that it's obvious that host is actually the top level domain. You, of course, are free to leave off the trailing dot if you want to, functionally it makes no difference, it's purely cosmetic. I'll go ahead and run this. Now let's scroll down to line 20. And finally here we create the hosted zone and save the results as a variable called zone. I'll execute this and that's it. Next, let's take a look at the zone properties just to verify that everything looks good. Go down to line 23 and we'll run this just to view the properties of the zone we created. We've got the name, benpiper. host, and there are two resource record sets, which of course, are the SOA and name server records. Let's just take a look at these two record sets, again, just to refresh your memory. To do that, I'm actually going to use nslookup. Let's go down to line 26. Now the first thing we're going to do is grab the name of the first name server in the delegation set and store it in a variable name firstns. Let's take a look at the name of the first name server, and it is not specified-806. awsdns-36. net. Now these are some rather cumbersome names. Now what we want to do now is query this name server for all resource records under the zone benpiper. host. Let's jump down to line 28. Now look at the nslookup command here, the -type=any flag causes nslookup to ask for all records. The $zonename variable tells nslookup the name of the zone we're interested in, which again, is benpiper. host, and the $firstns variable tells nslookup which name server to query, and that, of course, is the first name server in the delegation set. Let's go ahead and run this. Alright, awesome. The name server has returned four name server or ns records, which as you can see, are the exact same name servers in the delegation set. Notice, however, that they are not in the same order. They actually look pretty random. Now take a look at the next record down. This is the start of authority, or SOA, record. Again, it specifies the primary name server. You recognize that, it's the first name server in the delegation set. The primary name server is, just as the name suggests, the name server that Route 53 originally stores the zone records on. It's where the zone records start out, hence the term start of authority, or SOA. The name server in SOA records gets started here first and then those changes propagate to the other three servers up here. Now that propagation generally takes less than a minute, but it can take several minutes, and that is why I wanted to query the primary name server because I know that it will always have the latest records for the zone. Okay, so far so good. Our zone is set up correctly on the Route 53 side and we have the set of name servers hosting the zone. Next, we need to tell the registrar of the domain about these name servers.

Adding Name Servers to a Registrar
In this clip I'm going to update my registrar with the name servers in the delegation set I just created. The process for doing this with your registrar is likely going to be different. So, if you're following along, you may need to consult their documentation to find out it works. Chances are, however, that you'll be able to figure it out on your own. Anyway, let's jump over to the Route 53 web console. Here I am back at the hosted zones and you can see there's the hosted zone I just created in PowerShell. Let's go ahead and click on the domain name here, and there are our two resource records. Now the first thing I'm going to do is create another resource record pointing to the web1-east instance. We're going to use this to verify that domain name resolution works correctly after we update the name servers. Now I'm going to click on Create Record Set up at the top. Under Name, I'm going to put web1-east. The record type is going to be A, which is an IPv4 address. And the value is going to be the public IP of web1-east. And there we go. This is going to create an A record for web1-east. benpiper. host with the value of that instance's public IP address. Notice that I've left the defaults on the rest of the options here because I'm just creating a standard simple resource record, just like you do with any other DNS service. There's nothing special or unusual going on behind the scenes here. This is just a plain old resource record. Now let's go ahead and create this and now let's jump back to the command line. Now the command I'm going to issue here is nslookup web1-east. benpiper. host and the name server I'm going to query is going to be the first name server in the delegation set list, which as you remember is the primary name server for zone. We had that stored in the first ns variable. And not surprisingly, that resolves to the correct IP address. Now by the way, if you don't specify a record type, nslookup will default to the A record type. Now let me ask you a question, if I open up my web browser right now and browse to web1-east. benpiper. host, will it work? Well think about what has to happen, my machine has to resolve that domain name to an IP address. How does it do that? It does it by querying the DNS server or servers that it has configured. Well what are those? Well, let's just enter nslookup. Now the name server I have configured on my machine here is 192. 168. 88. 55. This is the local DNS server on my network. For a home user, this is generally going to be either their internet router or a DNS server provided by the user's internet service provider. In an organizational environment, this is usually going to be a Windows domain controller or just a Linux DNS server. The point is that this is not a Route 53 name server. Now if I type web1-east. benpiper. host, it tries to resolve an A record for that address, but it can't, it fails and says non-existent domain. But where exactly is this error coming from? Well let's find out. Let's try to check the SOA record. We'll do set type=soa and I'll type benpiper. host. Now this is interesting, it says the primary name server is dns1. registrar-servers. com. This is the DNS server that belongs to the registrar I use to register the domain name. This server has no record for the domain name web1-east. benpiper. host, that's why it gave that non-existent domain error. Now as far as this name server is concerned, that domain name does not exist. It does, however, exist in the zone hosted on Route 53. So what I need to do then is go to the registrar and tell them that I want to update the name servers to point to the Route 53 name servers in the delegation set we created earlier. Speaking of which, what are those name servers again? Well let's drop back to PowerShell, I'll type exit here, and let's scroll down to line 31, and we'll go ahead and run this to view those name servers again. There we go. Now I need to tell the registrar that I want to use these name servers for the domain benpiper. host. To do this, I'm going to log into the management portal for the registrar that I used to register the domain name. If you're following along and have an already registered domain name that you want to use, you should log into your registrar's management portal now. Now here I am at the domain name management page for my domain name benpiper. host. Again, this is not Route 53. This is name cheap, which is a third party registrar I used to register the domain name. Now if you're following along, locate the option to change the name servers for the domain. That's going to be down here, if I scroll down, there's name servers right there. Now I'm going to click the dropdown here where it says Namecheap BasicDNS, and specifically the option you're looking for will let you specify your own name servers. Nothing here explicitly says anything about custom name servers, but I do have an option for custom DNS, so I'll click that, and it gives me fields to enter my enter custom name servers. In these fields, I'm going to enter the four name servers from the Route 53 delegation set. We'll start with the primary one, which is that ns-806. We'll move on to the next one in the set, and then I'm going to click Add Nameserver so that I can add the other two. Add Nameserver again, and I'm sure you figured out that I'm simply copying and pasting these. Alright, once I have all those in I'm going to click the checkmark here to save. And it says DNS server update may take up to 48 hours to take effect. Now by the way, if your registrar does not allow you to add all four name servers, you can add just the first two and you will be fine. DNS requires a minimum of two name servers and anything beyond that is just for redundancy. The next question that might be on your mind now is how long do I have to wait before I can actually start using Route 53? That is, how long will it take for the rest of the internet to realize that those Route 53 name servers are now the authoritative name servers for the domain? Well that is what we're going to cover next.

Understanding NS Record TTL Values
How long it takes for the change to take effect depends upon the time to live, or TTL, value of the name server records as they are on the existing name servers. In this clip, we'll check the TTL value and figure out just how long we have to wait. Let's jump back over to PowerShell. Understand when I say the existing name servers, I'm talking about the registrar's name servers, the ones that we saw originally, not the Route 53 name servers. Now here we are, back at the command line, and let's go ahead and jump back into our friend nslookup. Here we're going to set the type to ns for name server and we'll type benpiper. host. Now notice we still have the old name servers, dns1 and dns2. These were the original records from the registrar. Now how long will other DNS servers on the internet continue to use these servers? Well we have to look at the TTL to find out. To do that, I'll type set debug and then benpiper. host again. Now the TTL for the name server records is 29 minutes and 36 seconds or 1776 seconds. The DNS server that I'm querying here, which again, is my local DNS server, is going to continue to hang on to these old name server records until the TTL expires. This means that the change we made at the registrar level is not going to propagate to the internet for at least 29 minutes and 36 seconds, it's actually less than that now because I've been talking since I ran this query. Now as I mentioned, the TTL came from the name servers themselves. That's kind of hard to visualize. So let's take a look at it. We'll exit out of nslookup so that I can run this nslookup command, nslookup -type=ns -debug benpiper. host and I'm going to query dns1. registrar-servers. com, registrar is a little bit tricky to type, and hit Enter. Okay, now because of the debug it spits out a lot of output. Let me actually move this up so we can see more of it. What we're interested in here is the name server records. Now look at the TTL, it's 30 minutes. Now check this out, look where it says auth. answer. This means authoritative answer. This server that we're querying is an authoritative name server for these name server records. Now recall what an authoritative name server is, it's the author of a zone. It's where the zone originates. Hint, these records are permanent, they don't expire. The purpose then of the TTL is to tell other DNS servers how long to cache these records. The TTL is 30 minutes, so other DNS servers, such as my own local DNS server, cache these name server records for 30 minutes. When the 30 minutes is up, my DNS server will then contact the name servers for the top level domain, which is host dot, then it will retrieve the updated name server records. If you couldn't follow that, I don't blame you, that's very difficult to visualize. So let's take a look at this. We'll do nslookup -type=ns, and what we're doing here is we want to look at the name server records for the host top level zone. Let's hit Enter here. These are the authoritative name servers for the host dot top level domain. Remember how Verisign is the registry operator for the com zone, these name servers belong to the registry operator for the host zone. And as you can see here, we've got a, b, c, and d. nic. host.

Changing the Negative Caching TTL
Even if many of the DNS concepts we've covered so far are familiar to you, there's one you've probably never even heard of, and that's the negative caching TTL. But even if you've never heard of it, chances are you've encountered it. The best way to understand the negative caching TLL is to see its effects. In this clip, we're going to create a simple resource record and when we go to try to resolve it, it's not going to work. It's not going to work because of this crazy thing called the negative caching TTL, which we are going to change. Yes, this is something we can actually configure. I know this whole thing sounds a little ambiguous, like I said, the best way to understand it is to see it. So let's jump back over to PowerShell. We're going to start by creating an A record for test. benpiper. host. Now here I am querying for an A record. That record, of course, doesn't exist we haven't created it yet. Now why am I trying to resolve a non-existent domain name? Well you'll see in a moment. But first let's jump over to Route 53 and create the record. I'm going to go ahead and click on Create Record Set here, and then under Name I'm going to do test. benpiper. host and for the value I'll paste in the value of web1-east. Now since we're talking about TTLs, notice the TTL value is 300 seconds or 5 minutes. Recall from when we looked at the TTL value for the name server records, this functions exactly the same way, it controls how long other DNS servers will cache this record. Keep in mind, however, that this is not the negative caching TTL. We're going to get to that one in a moment. Alright we'll click Create to create this wonderful record. Now let's jump back over to nslookup and try to resolve this again. Alright I'm going to do test. benpiper. host, and it still says non-existent domain. This response we're getting here from our DNS server is called a negative answer. Why are we getting this? We just created this record. Naturally you might think that, well we just haven't waited long enough. Well, let's wait 30 seconds and try again. As a matter of fact, it's probably been at least 30 seconds since I created it, since I've been talking, so let's try running this query again. Nope. Same problem. What's happening is that the DNS server is caching the negative answer. Remember that before we created the record, we tried to resolve test. benpiper. host. The first time we ran the query, our DNS server got a response from Route 53 saying effectively that this domain doesn't exist because at the time it did not exist. We then created the record. The next time we ran that query, my local DNS server did not resend that query to Route 53. Why not? Because it already had cached or saved the original negative answer. It checked its cache, saw that it already had a negative answer, and it returned that negative answer to us. So the next question is, how long is the DNS server going to cache this negative answer? In other words, when it is going to re-query one of the Route 53 name servers to get the record that we just created? Well let's jump back to the web console. Now in the list of record sets, click on the SOA record. In the Value field, scroll down so that you can see all the way to the very end of the record. Notice that very last number, 86400. This is the negative caching TTL given in seconds. I must issue a terminology alert here, this is sometimes called the default TTL because that's what it was originally called. But the modern term is the negative caching TTL. The negative caching TTL controls how long a DNS server may cache or remember a negative response. Now how long is 86400 seconds? That's 1 day. Now before you get too excited and start throwing things around the room, understand that this is a maximum value. DNS servers not supposed to cache a negative response for more than 1 day, but we actually do not have to wait 1 day. And here's why, look at the TTL value for the SOA record itself, it's 900 seconds, which is just 15 minutes. So what should happen then is that our DNS server should use the lower for the amount of time that it will cache the negative answer. In this case, 900 seconds is lower than 86400 seconds, so we should have to wait at most 15 minutes, actually less than that now. Once that 15 minutes is up, we should be able to resolve the record that we created. Let's jump back over to nslookup. Now we're not going to actually wait 15 minutes, but I want to show you how you can see how much time you have left. Let's do a set debug, we'll do test. benpiper. host. Look at the TTL under the authority records header. That's how long until the local DNS server will retry the query against one of the Route 53 name servers. So the lesson here is this, after you create a resource record for a domain name, wait a good 30 seconds or more before attempting to resolve that domain name. Now by the way, do you recognize the information here? This is actually the SOA record, in fact, authority record is just another term for the SOA record, whereas the negative caching TTL, well remember I said earlier that this used to be called the default TTL, they're the same thing. So to reiterate, to find out how long you'll have to wait, just look at the TTL and the negative caching or the default TTL, take the lesser of those two values and that's how long you'll have to wait. And that's a blessing for us really because who wants to wait a full day? That just seems ridiculous. Thankfully you can adjust these to make them lower if you want to. Alright let's go ahead and exit nslookup and jump back to the Route 53 console. Now the only time you'll encounter a problem with negative caching is, like I said, when you're doing exactly what we're doing, creating new resource records. So to avoid having to wait 15 minutes every time we inadvertently make a query too soon, let's go ahead and change the negative caching TTL to 60 seconds. To do that we'll just go ahead and highlight the 86400, change that to 60, and then of course, save the record set. And that is all there is to it.

Registering a New Domain Name with Route 53
In this clip, I'll show you how to register a new domain name using Route 53. When you register a domain name in Route 53, it does almost all of the hard work for you. It creates a public hosted zone for the domain and it updates the appropriate top level domain registry with the correct name server entries. Sound familiar? Route 53 performs all of those steps that we just performed manually. Now in this demo, I want to show you where to go to register a domain name using Route 53. I'm not actually going to register a domain name, but I'll walk you through enough of the process that you'll be able to follow through on your own, if you so choose. Let's jump back over to the Route 53 web console. Now here at the primary dashboard, look down at the bottom left and click on Registered Domains. You can see I have a domain registered here. We want to pretend to register a new one, so go ahead and click on the Register Domain button. And you can start searching for a domain name by simply typing in this text field. I'm going to search for benpiper. net and then I'll click Check, and as you can see here, it decided that I was searching for benpiper. com even though I did type. net, you have to be a little bit careful with this thing, I have had this do this more than once. You may actually have to click on the top level domain so that it shows up in the dropdown. Click Check again and there we go, benpiper. net is available. Now I'm going to click Add to cart, add it to my shopping cart, this is very Amazon-ish, adding things to a shopping cart, and then here I can choose how many years that I want to register the domain for. I can actually have it for up to 10 years before we have to renew it, let's do that just for fun. Alright let's scroll down to the bottom and click Continue. Here it asks for the registrant contact information. So we've got registrars, registries, and now registrants. That's a lot of words that start with regis. Anyway, under the contact type, you can select company, person, association, or public body. I'm not going to fill this out, you can see it's actually already mostly filled out. But after you fill it out, scroll down to the bottom, all the way to the bottom, and then click the Continue button. Once you do that, you'll be prompted to agree to something and then you'll be able to complete your purchase. The cost of the domain name itself will get billed to your AWS account and Route 53 will automatically create a hosted zone for your new domain. That's it, pretty simple. Now, by the way, let me scroll back up here and I want to jump back over to the registered domains. As I mentioned before, I already have a registered domain name, coastalcarolinanetworks. com, but you will notice that that hosted zone doesn't exist. It doesn't exist because I deleted it. I was able to delete it because it's just a regular public hosted zone. It's no different than the hosted zones we've created manually.

Creating CNAME and Alias Records
If you've been using DNS for awhile, you may have created CNAME or canonical name records before. A CNAME record points one domain name to another, in other words, it lets you create an alias for an existing domain name. Now in light of the title here, that may seem confusing. If a CNAME record is an alias, what's an alias record? Well the terminology actually gets rather confusing here, and we're going to address that. But let's start by talking about how a CNAME, or canonical name record, works. Let's say that I have a simple A record for web1. benpiper. com. What I want to do is point www. benpiper. com to the same IP address. Obviously I could just create another A record, but there's a better way. I can create a CNAME record. In the CNAME record, www is the alias and web1. benpiper. com is the canonical name, or CNAME. When a client tries to resolve www. benpiper. com, they'll get redirected to web1. Okay, well that's pretty easy to understand, but if that's a CNAME record, what's an alias record? Well, like I said, the terminology is confusing. The best way to understand the difference is to create both, so that's what we're going to do now. Let's jump back over to Route 53. The first thing we'll do is create a CNAME record. We'll click on Create Record Set, under the name we'll type www and under record type we're going to select CNAME - canonical name. For the TTL value, I'll put 60 for 60 seconds, and the value is web1-east. benpiper. host. Now notice that web1-east is an existing domain name. It has an A record that points to the public IP address of web1-east. Here's where the terminology can get a little weird. The name, www, is the alias. The value, web1-east. benpiper. host, is the canonical name, or CNAME. Now please understand that what we're creating here is not an alias record, it's a CNAME record, but the www is an alias. Again, I know that's confusing, but that's the terminology. Let's go ahead and create this. That looks good. Let's jump back over to the command line. We'll jump into nslookup www. benpiper. host. Now look at what it gives us. The name is web1-east. benpiper. host. Again, this is the canonical name. The address is the IP address of web1-east, which again, is coming from the A record for web1-east. benpiper. host. The alias is www. benpiper. host. The point of all this is that we should be able to just jump over to a web browser and browse directly to the alias address. Let's go ahead and try it. We'll jump over to Chrome. And here in a fresh new Chrome tab, I'm going to type www. benpiper. host and it works. Now look at the host header. It shows the alias, starting with www, but this is still very much the same web server that we've been connecting to, so this looks good. But there is another consideration. A lot of times people don't think to put this www in front. Someone might try to browse to just benpiper. host. How can we make sure that that works as well? Well to do that, we need to create what's called an apex record. Let's jump back over to Route 53. We're going to create an apex record. There's actually two ways to do this. The first way is this. We'll click Create Record Set and the name we're just going to leave blank. I'm not going to put anything in here. The type will be A, and the value is, of course, going to be the instance IP address. This, again, is web1-east. Now if we were to create this, someone could browse straight to benpiper. host and they would hit this IP address. But here you might think, wait a minute, why not just create a CNAME record? Why put the IP address here? If the IP address were to change, we would have to change this record and the www record. So specifying a CNAME instead of an IP address would seem to make sense here. Unfortunately that's not actually allowed. Let me show you. Let's go to type and we'll change this from A to CNAME. The value we'll change to web1-east. benpiper. host and then I'll click Create. And we get an error saying a CNAME record is not permitted at the zone apex. And this rule is part of the DNS specification. It's not something quirky with Route 53. So if you want to create an apex record, you cannot use a CNAME for that, it has to be an A record. So let's go ahead and change this back to A record, and that brings us to the second option. Notice where it says alias, go ahead and click Yes right here and now we have a field for alias target. Go ahead and click in that field and let's scroll all the way down to the very bottom. Now at the very bottom, it shows us how our A record for web1-east. Let's go and click on this one. Understand that this is not a CNAME here. We're not creating a CNAME record, even though it seems very similar. Let's go ahead and click Create. Alright you can't create a CNAME record of the zone apex, Route 53 does let you create an alias record, which is just an A record pointing to another A record. If you look there at the very top of the list, you can see the name, benpiper. host, with a type of A and the value is ALIAS web1-east. Now let's try to browse directly to the zone apex. Let's jump back over here. And here I'm going to type http://benpiper. host and I'm specifying the http before because without it, Chrome will actually try to add a www at the beginning and that's exactly what we do not want. Super. This works. The host header shows just benpiper. host, which is what we browse to. So we have a www record and a zone apex record, both pointing to web1-east.

Chaining Resource Records
Right now the zone apex and www records are pointing to web1-east. If a user browses to benpiper. host or www. benpiper. host, they will land on web1-east. Now suppose we want to point the zone apex and www records to web2-east instead? Well that means we'd have to change two records. Not a huge deal, right? But wouldn't it be nice to be able to accomplish the same thing by changing only one record? Fortunately we can do just that. In this clip I'll show you how to chain together resource records in such a way that changing one record also changes all the rest. Let's jump back over to the Route 53 web console. Let's go ahead and create an A record for web2-east. Create a record set, web2-east. This is an A record, and for the TTL value, we'll specify 60 seconds, and the value is going to be the instance IP of web2-east. Click Create. Okay, it is created. Now rather than manually changing the zone apex and www records to point to web2-east, we're going to create a chain of records. It's a lot easier to understand this if you see it, which is true of pretty much DNS related. So I'm going to create the chain first and then explain it. Let's go ahead and click on the CNAME record for www, right here, and we're going to change the type to A. We'll set alias to yes. And for the alias target, we'll select web1-east. And then we'll click Save Record Set. Now click on the zone apex record. Click in the alias target field, go ahead and clear out what's already there, we'll just backspace over all this, and then browse down to the bottom. Now here you can see the record sets in the hosted zone. Click on the www. benpiper. host and then click Save Record Set. Now look at this, we've got a chain of resource records. Starting at the zone apex record, we can trace this chain. The zone apex A record points to www. benpiper. host as an alias. The A record for www points to web1-east, and that A record points to the IP address of web1-east. So let me ask you a question, now if you want to point both the zone apex and www records to web2-east, what do you have to change? That's right, you only have to change the www record. So let's try that. Click on that record here, go to the alias target, we'll go ahead and clear everything out of here. Scroll all the way down until you see web2-east, click that, and then click Save. Now if we browse to benpiper. host, we should hit web2-east. Let's try it. Let me go ahead and just refresh here, and it does not seem to be working. We're still hitting web1-east. Why is that? Did you catch it? Let's go back to Route 53. Remember that we were originally pointing to web1-east? Let's click on that A record here. Look at the TTL, it's 300 seconds, that's 5 minutes, see the local DNS server that I'm using is actually caching this record. It still thinks that benpiper. host should resolve to this IP address. Now what I should have done, ideally, was change this to something like 60 seconds so that the TTL would have gotten flushed out and we would have hit web2-east. So what this means is that I'm going to have to wait about 5 minutes before I can actually see my change take effect and that's pretty much the nature of the beast when it comes to DNS. There's a lot of waiting involved, particularly when you're setting everything up for the first time. Well since we have to wait 5 minutes anyway, what do you say we go back to the command prompt and see exactly how long we have left to wait? Let's use nslookup. We'll do nslookup -type=a benpiper. host, and of course we're still resolving to web1-east. I want to actually do a debug here, -debug, and if I scroll up just a hair, we can see that I have 2 minutes 4 seconds left before the TTL expires. Alright, well, we've waited this long, we can wait 2 more minutes. Let's scroll back down here and then let's run this again. Oh we have about 9 seconds left. We'll run it again, this time without all the debug information, and yes, there we go. We are finally getting the correct, or now correct, IP address. Let's jump back over to Chrome. Back over to the tab we go and we will hit Reload, and bingo, we are now hitting web2-east, as you can see by the public IP. This works. Let's go ahead and try www, and indeed that also works.

Creating Wildcard Records
Well thank you for sticking with me so far. We are almost done with this module, and in this final demonstration we are going to create something called a wildcard record. Wildcard records create synthetic records based on the query. Now what does that mean? Well here's how it works. In this clip, I'm going to create a wildcard record for *. benpiper. host. That will point to www. benpiper. host. The effect of this is that when anyone tries to resolve anything. benpiper. host, let's say it's hello. benpiper. host, they will get redirected to www. An advantage of this is that if you use a lot of subdomains and you don't want to have to create separate records for each one, you can actually just create one wildcard record and it will cover all your bases, so to speak. Let's go ahead and check it out. As you might imagine by this time, we are going to create yet another record set, we'll click the Create Record Set button, and under the name I'm going to put a star or an asterisk. This will be an A record, and for alias we're going to select yes, and the target name is going to be www, which we always have to scroll all the way to the bottom to get to those record sets, we'll select that, and then of course, create the record. Now, let's jump over to Chrome. Now let's jump over here and we'll try to browse to hello. benpiper. host. Now remember that www points to web2-east and that's exactly the server we're hitting here. But check this out. This is pretty neat. If I go to hello. again. benpiper. host, that works also, alright. But what about this one, what if I do test. www. benpiper. host? Remember, we already have an explicit record for www, but this is test. www, which is different. And so the wildcard catches this one also. So you're starting to see how this works. Now I want to show you one more thing before we close out this module. Let's jump back over to our list of record sets and now let's delete the wildcard record. It's right here. I'll go ahead and delete the record set and confirm, yet I do want to delete it. Now we're left with an explicit record for www down here, but no wildcard. Let's jump back over to our tab here in Chrome and let's try to browse to test1. www. benpiper. host, and that works. Alright, let's try a different one. Let's try just something random, test900, ah that does not work. Okay. Let's try test2, that doesn't work. Okay. Why isn't this working? Well now that we've deleted the wildcard, there's no record that matches test2. www and so we get a failure. Now why didn't we get a failure initially, when I initially typed in the test1. www, it worked, and then it stopped working. Well that's simply because it typically takes a few seconds for Route 53 to catch up with your changes. But as you can see now, the wildcard is definitely not working. If I type goodbye. benpiper. host, that's not getting us anywhere. So that's wildcard records. Alright, that is it for this module. Before moving on, let's jump back over to the resource record set list again. And we want to delete the zone apex record and the www record. So there I have it already selected, we'll delete the www record and the zone apex record is the one up here at the top, I will delete that one. And so we're going to go ahead and leave these records here in preparation for the next module.

Summary
Wow, that was a big module. I hope that you see why I made such a big deal about going over DNS concepts and terminology at the beginning of the course. I wanted you to be able to dive right in and start using Route 53 for yourself because, honestly, that's the best way to learn it. In this module, you learned now the domain registration process works at the DNS level. After that we covered how to use an existing domain name with Route 53. We looked at two different ways you can acquire a list of Route 53 name servers to use with your domain name. The first way is to create a public hosted zone. This causes Route 53 to automatically assign four name servers to your zone. The second way is by creating a reusable delegation set, which allocates the name servers first, and then it's up to you to associate them with a zone, and you have to use the AWS API for that, right now you cannot do it through the web console. After that we looked at how to update your domain's registrar with the Route 53 name servers. This process, of course, differs by registrar and it's something you may need to dig into on your own to figure out. We then briefly looked at how to register a new domain name with Route 53. When you do this, Amazon does all the work for you. They register the domain, they create the hosted zone, and they update the registry operator with the correct name servers. The only thing you have to do is create the individual resource records for your zone, and that's the last thing we covered, how to create simple A records, CNAME records, and alias records using the web console. Last but not least, you learned a skill that's going to come in handy later on and that is chaining resource records together in such a way as to make updating those records easier. Alright, in the next module we're going to cover health checks and failover records. Together these let you reroute traffic away from failed instances and to healthy instances, or even to a static web page. Not only that, configuring these is easy once you understand how all the pieces fit together. So join me please in the next module.

Configuring Health Checks and Failover Records
Module Introduction
Welcome back, my friends. In this module, you're going to create health checks and failover records. Conceptually these two things are really easy to understand, but they can be a bit tricky to implement. Here's our current lab environment. Notice over on the right, there's a table containing a simplified version of two of our resource records. There's one record for web1-east and another for web2-east, each pointing to the respective elastic IP address. Notice the routing policy for these is simple, we've seen that before when creating records, but I haven't explicitly addressed it. The simple routing policy just means that the record is a standard resource record, no different than what you'd create with any other DNS service. For example, web1-east. benpiper. host always resolves to the IP address 52. 206. 88. 55, no exceptions. In contrast to a simple routing policy, in this module we're going to add two more records, which use a failover routing policy. Notice both records have the same name, www, the top record is the primary and points to web1-east and the record below it is secondary and points to web2-east. Now when a client tries to reach www. benpiper. host, Route 53 will return the IP address of web1-east because that's the resource listed in the primary failover record. Now let's say that web1-east crashes, someone shuts it down or the web application crashes or something like that. When another client comes along and tries to browse to www. benpiper. host, Route 53 will return the secondary failover record pointing to web2-east. So what you have here is an active/passive scenario, if you're familiar with that term. The record pointing to web1-east is always the primary or active record, unless that instance fails, in which case the secondary, or passive record, pointing to web2-east then takes over. That raises the obvious question, how does Route 53 know when web1-east is down? The answer, health checks. Before you can implement failover records, you need to create some health checks, and that's what we're going to do next.

Creating Health Checks
In this demo you'll start out by creating two health checks, one for web1-east and another for web2-east. Pretty straightforward. Let's jump over to the Route 53 dashboard. Over on the left side menu, click on health checks. And then click the button that says Create health check. We'll start off by creating a health check for web1-east, so we'll name this one web1-east. Now it gives us three different options for what to monitor, an endpoint, the status of other health checks, which is called a calculated health check, or the state of a CloudWatch alarm. We want to check the status of web1-east, which is an endpoint, so we'll select endpoint. Let's scroll down a bit. We can specify the endpoint by either IP address or domain name. For the protocol, click the dropdown here, we can select HTTP, HTTPS, or TCP. Which protocol you choose will change how the health check operates. If you choose HTTP or HTTPS, the health checkers will send an HTTP request to the endpoint specified in the IP address. Let's go ahead and select HTTP and we'll populate the IP address field. Now by the way, the IP address must be a public IP, it cannot be the private instance IP. Now when the health checkers send the HTTP request, they can optionally pass a host header value in the request header. That's what the host name field is for. This is useful if the endpoint you're checking hosts different websites for different domain names. We're not doing that here, so we can just leave this blank. The port, we'll leave as the default port for HTTP, which is TCP port 80, and lastly, the path is the path that the health checkers will use in the request line of the HTTP request. If we leave this one blank, it's effectively the same as just browsing to http://52. 206. 88. 55, the IP address of the instance, with nothing else in the URL. We're not specifying a path. Okay now quickly, I want to show you something else. Click on the protocol dropdown again, and this time select TCP. Notice that all of the HTTP specific options disappear, there's no option for specifying an HTTP header or a path. That's because a TCP based health check only attempts to make a TCP connection to the endpoint. This is useful if you want to check some TCP based service like SSH or FTP. You, of course, would need to change the port appropriately, but the point here is that health checks are not limited to web servers. Alright let's go ahead and change this back to HTTP, and as you can see, it remembered our settings. Now let's look down a bit further and expand the advanced configuration section. We have two options for the request interval, this is how often each health checker performs a health check. We get only two options here, 30 seconds or 10 seconds. The thing to keep in mind here is that there are many health checkers. Now hover your mouse over the little i icon off to the right. It says typically about 15 health checkers check the health of a specified endpoint. If you choose an interval of 30 seconds, your endpoint will get a request every 2 to 3 seconds. Now when I read that I was like, what? That seems a little extreme. But we can actually control this by adjusting how many health checkers perform this health check, which we will do in a moment. But first, let's change the failure threshold here to 2. This controls how many times an endpoint must pass its health check to be considered healthy, and how many times it can fail its health check before it's considered unhealthy. I find 2 to be a good number for this, but you can set this as low as 1 or as high as 10. Now the next two options are what I call premium options because they cost extra. String matching lets you condition a health check based on a string in the response body. So you may not be satisfied with a successful HTTP request. String matching is useful if you want your web instance to respond with a specific string in order to be considered healthy. Let's go ahead and select yes here, and in the search string we'll type READY. So for instance, if you're running a web application and it displays some text like ready to indicate that the application itself is healthy, this is a useful feature. We're not going to use this, so I'm going to go ahead and change this back to no. Now the latency graphs option is just what it sounds like, it tracks latency and presents it as a graph on the health checks page. The invert health check status option also does just what it sounds like. If an endpoint is healthy, inverting the status will make it show unhealthy. Now lastly on this page is the health checker regions option. As I said, there are multiple health checkers in different regions. Here you can choose which regions you want those health checks to originate from. AWS offers a recommended list, but you can customize it and remove any you don't want. Now I'm going to remove the last four in the South America and Asia Pacific regions, just click the x next to each one of them, and oops I accidentally deleted the wrong one. Well that's okay. I'll go ahead and delete this Asia Pacific one and Singapore and we can just click select regions down here and we can add back any region we'd like. I'll go ahead and add back Ireland herd. And there we go, we now have four health checker regions. Now what this is going to do is this reduces the intensity with which our instances get hit with health checks. So instead of every 2 to 3 seconds, it'll be more like every 4 to 6 seconds. Alright, that's it for this page, let's click Next. We have an option now to create a CloudWatch alarm. I'll stick with no here, and then finally, I'll click Create health check. Now initially the status will show unknown. Remember we configured a failure threshold of 2 and the request interval is 30 seconds, so it will take about 1 minute before the endpoint shows healthy. After waiting about 60 seconds, I'll go ahead and refresh here. And now the status is healthy. Next, we'll create another health check for web2-east. I'll walk through this one a little bit faster. We'll click on Create health check. Name is going to be web2-east. We want to monitor an endpoint. We will specify the endpoint by IP address. The protocol, of course, is HTTP. And we'll enter the IP address of web2-east. We'll leave the host name blank. The port will be 80 and the path will also be blank. Let's go down to Advanced configuration. We'll change the failure threshold to 2, not 32, just 2. And we'll customize the health checker regions to remove the last four, and that leaves us with four, and let's go ahead and click Next. We do not want to create a CloudWatch alarm, but we do want to create the health check, so let's click Create health check. Next, we'll create some failover records to use these health checks with.

Creating Failover Records
Now that we've got our health checks created, it's time to create two failover records that make use of those health checks. Again, the primary record will point to web1-east and the secondary will point to web2-east. As long as web1-east stays healthy, Route 53 will resolve www to its elastic IP address. But if web1-east fails, Route 53 will then start resolving www to web2-east. In this clip, you'll create those two failover records we just discussed. After that, we'll force a failure of web1-east and verify that Route 53 fails over to web2-east. Let's jump back over to our hosted zone and create some records. Let's go ahead and open up the hosted zone here. I'm going to adjust my pane out a little bit so we can see this better. Let's go ahead and click on Create Record Set. Now under the name, we'll put www, the type is going to be IPv4, and for alias we want to select yes. Now under the alias target, we're going to select web1-east and the routing policy here is going to be failover. Now once we select failover, we get a couple more options here. We get two options for the failover type, primary or secondary. We want this record to be the primary, so we'll stick with that. In the set ID field we need to enter a unique string to identify this record. AWS populates this with www-Primary, which is fine, so we'll stick with that. Now, the next two options sound very similar. Evaluate target health and associate with health check. Let's hover over evaluate target health to view the tool tip. It says specify whether you want Route 53 to check the health of the alias target. The alias target must be health checked or this setting has no effect. Now here's where this gets confusing. Is the alias target being health checked? Well what is the alias target? Let's scroll up. It's another resource record. It's not the web1-east instance itself. Are we health checking this resource record? No, in fact it's not even possible to health check a simple resource record, which is what this is. Again, I know this is confusing, but it does get easier the more you work with health checks. Let's scroll back down. So we'll leave evaluate target health as no. For the next option, associate with health check, choose yes. Scroll down here, and then we can select one of the health checks that we created. We, of course, want to select the one for web1-east and there we go. And that's it. We go ahead and click Create to create this first primary record and we can see it over here, there it is in all its glory. Alright now we will repeat the process for web2-east. I'll move through this a little quicker. We'll create a record set here. The name here is also going to be www, it's an IPv4 address, and for alias we want to select yes. Now under the alias target, this time we want to select web2-east. The routing policy will, of course, be failover, and this time we want to select secondary. Scroll down a bit more here and it names the set ID www-Secondary, which is fine. Evaluate target health, we will leave as no, and associate with health check, we want to do yes and, of course, the health check to associate web2-east. Perfect. Alright this all looks good, let's click Create. Now, let me shrink this a little bit. Now please take a look at the alias records the failover records point to. Let's start with web1-east. Notice that the TTL here is 60 seconds. It's important to have a low TTL because when a failover occurs, DNS servers throughout the internet will still hold on to the old record until the TTL expires. Let's go see this in action. Let me open up a new tab in Chrome here and I'll do www. benpiper. host. Now notice we hit web1-east. Okay, now let's open up an SSH session with web1-east and shut down the web server. Now here I am on web1-east and because the web server is running inside a Docker container, I need to stop that container, and to do that I need to find out the container id. So to do that, I'll do sudo docker ps and then sudo docker stop and then I'll go ahead and paste in the container id here, and that stops the container. Great. Now let's jump back over to Chrome. I'm going to go ahead and reload the web page by hitting F5 and we get an error, the site can't be reached. Why hasn't Route 53 failed over to web2-east? Well remember the failure threshold we set in the health check settings. We set it to 2 and the health checker interval is 30 seconds. That means web1-east has to fail two consecutive health checks before Route 53 considers it unhealthy. That takes about a minute. In addition to that, my DNS server is still caching the old record pointing to web1-east's IP address. So the bottom line is that we have to wait about a minute before we actually get failed over to web2-east. Alrighty, I've waited 1 minute and after reloading, we now hit web2-east. Route 53 has failed over, which is exactly what we want and what we expect to happen. What happens though if web1-east comes back up? Well let's find out. Let's jump back over to our SSH session with web1-east. Now I've hit my up arrow a few times to go back to the original command that I used to start the web server and I'll go ahead and hit Enter there. And once it restarts, notice that we're getting requests from the Amazon Route 53 health check service. If you pay attention to the timestamps, you'll notice that the health checks are coming in at anywhere from around 5 seconds to 15 seconds. Alright let's jump back over to Chrome. Again, it'll take about a minute for Route 53 to consider the instance healthy because it has passed 2 consecutive health checks. It's been about a minute now so I'm going to go ahead and hit F5, and just like that, we fail back to web1-east, or I guess you could say we success back to web1-east because it's no longer failing. Regardless, this is the exact behavior we want. When the primary fails, we failover to the secondary, when the primary comes back up, we fail back to the primary. Perfect.

Chaining Failover Records Together - Part 1
At this point, it may seem that there are a few downsides to failover records. One of the apparent downsides is that you can have only one secondary record. Or can you? If all you have are one primary and one secondary record and both endpoints go down, that leaves you in a bad situation. Fortunately Route 53 gives you a lot of flexibility. Recall from earlier in the course when you chained together resource records. Well we can do the same thing with failover records, except this time we're going to create a more complex chain. Take a look at the table on the right. Notice that the primary record for www points to the alias record for east. East is another failover record set and the primary record points to web1-east. Now here's where the magic happens. Let's say that both web1-east and web2-east go down. At that point the entire east failover record set becomes unhealthy. Now what happens when a client tries to resolve www? Well the www record set fails over to the secondary record, which points to the west alias record set. The west alias record is itself a failover record set and the primary record points to web1-west. Okay, I know this is a little bit difficult to follow because we're jumping all over the place here. Now if web1-west goes down, that leaves only the secondary record in the web record set and that points to web2-west. Now I have these records in a nice table format here and, to the casual observer, the way this works is not plainly obvious. Imagine how much more cryptic this becomes when you're viewing the resource records in the Route 53 console. It can get very tricky. That is why I recommend writing out your desired flow in either a binary tree or an outline format. Let's use an outline format. The name of the record I'll create is www. benpiper. host. The primary alias record will point to the failover group east. Within that group, the primary resource record is web1-east and the secondary is web2-east. The secondary alias record for www. benpiper. host will point to the west failover group. That group contains web1-west as its primary and web2-west as its secondary. By the way, how many health checks do we need for this? We only need four, one for each instance. We already have two health checks, so we need two more. We'll create health checks for web1-west and web2-west. We'll also create resource records for these instances. After that, we'll create a chain of failover records and test everything out. Sounds like fun. Let's jump over to the health checks console. We'll click Create health check. The name of this one is web1-west. I'm going to go ahead and pop in the IP address here. We're going to set the failure threshold to 2 and I'm going to remove 4 of these regions and then click Next and Create health check. Next we'll create another health check for web2-west. I'll put in the IP address of that instance here, and then, of course, the failure threshold will be 2 and we're going to customize our health checker regions so that we're not hammering this instance with health checks. Click Next. Don't want to create an alarm here, create health check. Now while we wait on these to show healthy, let's go create our failover records. Let's jump back over to hosted zones. Dive in here to the hosted zone, and then we'll click Create Record Set. The first one we'll do here is web1-west, it's not an alias. We're going to set the TTL value to 60 seconds. The resource data here is going to be the IP address of web1-west. The routing policy we'll leave as simple. And then click Create. Now let's create another one, this time for web2-west. Set the TTL to 60 seconds and then we'll paste in the IP address for web2-west. The simple routing policy is what we want and then click Create. Now let me go over here and just double check and make sure everything looks correct, and it does. Next we'll create a record set called west that will point to web1-west as the primary and web2-west as the secondary. So we'll create another record set. The name of this one is west. For alias we want to select yes. The target here is going to be web1-west. Now the way I have these named, it can get kind of easy to get mixed up, but web1-west is the one we want. The routing policy will be failover. We'll make this the primary record. And the set ID of west-Primary is perfectly fine for this. Under evaluate target health, we'll stick with no, and for health check we'll select yes, and then, of course, we will select the web1-west health check. That all looks good and we'll click Create. Now we need to create another record set, also for west. This time we're going to point this to web2-west. The routing policy will be failover. This is going to be the secondary record and a set ID of west-secondary is fine. And then we will associate this one with the web2-west health check. And by the way, if you notice there, when I click the dropdown and I hover my mouse over the health check, look at what it does. It shows us the IP address that the health check is checking, that's pretty cool. So web2-west is the one we want. Click Create. And there we go. Alright, looks good. Confusing, but it all looks right. Now speaking of confusing, remember that earlier we created two failover records pointing to web1-east and web2-east. Those are actually these two records right down here. You can see, this one is pointing to web1, this one is pointing to web2. Okay, now stick with me here. To save some time, we're just going to rename these from www to east. So I'm going to click this little pencil, I think it's a pencil, a green pencil, click that, and I can change the name from www to east, and notice that it very conveniently changes the set ID to east-Secondary. So I'll save this record set. I'm going to find the other www record right here, click the green pencil, change this to east, verify that it actually changed the primary set ID to east-Primary, and it did. So now Save Record Set. Now let me expand this a little bit here, just so that you can get a good look at it. We've got two west records, two east records.

Chaining Failover Records Together - Part 2
Now it's time to create the failover record set that's going to bring the east and the west failover record sets together. So yes, we have to create a couple more record sets. Click Create Record Set, and the name here is going to be www. This is going to be an alias. Now here, we are going to do something new. Under the alias target, let's scroll down here, just so that you can get some good context. We're looking for east. benpiper. host. East is going to be the primary, okay. Now let's scroll down, routing policy will be failover. This is the primary, Set ID wwww-Primary. That all looks good. Now under this, we're going to do something new. Under evaluate target health, this time we are going to choose yes. Why? Because the target here, east, is itself a failover record set which is being health checked. That is, it's associated with the health checks for web1-east and web2-east. If both of those health checks fail, then both of the east alias records themselves will become unhealthy. Here's another way to think about it. Click yes in the associate with health check and then, let me expand this out so we can see this better, look at the dropdown. If we were to associate this record with the health check, which one would we select? None of these actually make any sense here. We don't want this record to failover if just one instance goes down. We want it to failover if both web1-east and web2-east fail. In other words, we want Route 53 to treat those as a single unit and that's what the east failover record set is for. So for associate with health check, we want to do no for that. Evaluate target health is yes. Once again, the target east. benpiper. host, which is a failover record set. Okay I hope I made that clear. Let's click Create. Thank you for being patient with me, we've got one more to go. Let's click Create Record Set. Now we're going to create the secondary record, www, this is going to be an alias. The target name here is going to be west. benpiper. host. The routing policy, of course, failover, that's what this module is about, failover records. The record type is secondary, www-Secondary for the Set ID, and evaluate target health is yes. Associate with health check, no. Alright we're almost there, I promise. Click Create. We'll expand this out here, just so that we can look at everything or almost everything. I think we can squeeze everything here. Www points to the east and west failover record sets, west points to, of course, the two west instances, and east, if I scoot up a little bit here, points to the two east instances. Alright clear as mud, right. Alright, so after creating all those records, we want to wait 30 to 60 seconds just to give everything time to catch up with our super fast record creation. I think we've waited long enough. Let's jump back over to Chrome here and we're going to go to www. benpiper. host. Not much has changed here because we hit web1-east, as expected. Alright, what if web1-east goes down? Well let's go SSH back over there, shut down the web server again. Now here what I can do since I'm actually inside the container now, I can just do Control+C to break out of it and it stops the container. Of course, you know what I'm going to say next here, right? We have to wait for those two health check intervals to complete, which takes about 60 seconds. After waiting about a minute, very patiently I might add, let's jump back here to Chrome and refresh. Super. Now we hit web2-east. Remember, it's the secondary record in the east record set, alright. But what if this one goes down? Well let's go find out. Let's SSH into web2-east and crash the web server. I'll do a sudo docker ps to get the container ID, sudo docker stop and I'll just enter the first portion of the ID, which is 67, and there it goes, it has stopped. And of course, we have to wait about a minute for Route 53's health check to catch up. And what we can do while we're waiting, if you would like, is go back over to health checks and we can actually see the real time, or almost real time, status of each one of our health checks. Of course, web1-east is unhealthy and web2-east is still showing healthy. Now if I refresh it, yes it's still showing healthy. Now what we can do is actually click in the health check itself, go under health checkers, and we can see that each one of the health checkers in different regions shows a different status. EU Ireland, one of those shows success, the next one down shows failure: connection refused, as do most of them. So our health check is going to fail pretty soon here. We'll go ahead and refresh again. And now it's showing unhealthy. Super. Alright, so I'll wait a few more seconds here and then I'm going to go over here and refresh the tab in Chrome. Okay, now we hit web1-west. Both of the east records are unhealthy so the www record fails over to the west records, and web1-west is the primary record in the west record set. Okay so this is all working as expected, up until now, but what if this one goes down? Well, of course, you know what would happen. We would then failover to web2-west. But let's skip ahead here. What if everything went down? What if all four of these instances are just down? What happens then? Well let's go find out. Let's go over to web1-west and web2-west and let's bring down the web server on both of these. Sudo docker ps here on web1-west. Sudo docker stop, and then the first part of the container ID. Then I'm going to jump over to web2-west real quick, sudo docker ps, sudo docker stop, and then the container ID. Okay, so the web server is stopped on web2-west, it's stopped on web1-west, and of course on web1 and web2-east, we already know it's stopped because we saw those health checks failing. Alright, yes, once again, got to wait about a minute here, but once we do that, we're going to jump back into Chrome, try to reload and see what happens. Now since all of the web servers are down, it doesn't really make any sense to come back to Chrome because all we're going to get is an error page with no indication of which IP address Route 53 resolves to. If I do refresh, which I just did, the site can't be reached, of course, because there's no servers up. So let's go use nslookup. Let's jump back to the command line, here I am back in Visual Studio, and I'm going to do nslookup www. benpiper. host, and it resolves to this IP address. Well what is that? Well that's actually web2-west, web2-weest. benpiper. host. Yes indeed it is web2-west. So I haven't actually waited a minute yet, or maybe I have, I wasn't actually timing myself here. But regardless, the health checks have apparently not yet caught up. We'll wait a little while longer and then try it again. There we go. Now it resolves to the address for web1-east, even though web1-east is not healthy. So what happens here is that if all the resource records are unhealthy, Route 53 will serve the primary record. Well which primary record? We have like three different primary records. Well it falls back to the primary record set in the www set, which is the east record set, and the primary record set in the east record set is web1-east. Okay, I'm sorry, I know that's hard to follow. But after you play around with this for a little while, it does start to become second nature to you.

Failing Over to a Static Web Page
At this point, all of our web servers are down and showing unhealthy in their health checks. If someone tries to browse to www. benpiper. host, they'll just get an error page. But wouldn't it be nice if we could show them a nice static web page that says something to the effect of all servers are down, please try again later. Indeed we can. In this demo, I'll show you how to set up an S3 bucket for static website hosting. We'll then upload and index. html file, which is in the course exercise files, and that index page is what S3 will serve up. We'll then reconfigure the west secondary failover record to point it to the bucket. What should happen is that when all of the web instances are down, which they are currently are, anyone trying to browse to www. benpiper. host should see the static web page hosted from the S3 bucket. The records we end up with should look like this. Everything is the same except the secondary failover record for west will have an S3 bucket as the target. Alright, let's jump over to the S3 console. Go ahead and click the Create bucket button on the left. And under the bucket name, we'll put www. benpiper. host. The name here is all important, it must match what the end user is going to type in on their address bar. If they're visiting www. benpiper. host, then this bucket name must be the same. That's because S3 static website hosting matches the host header with the bucket name. If they don't match, S3 has no idea which bucket to use. Okay, for the region we're going to select the Northern California region and then click Next. We're going to go ahead and just leave all this disabled, click Next. Under manage public permissions, we want to select grant public read access to this bucket, and it gives us a rather scary looking warning, this bucket will have public read access. Well we want it to, so that looks good, go ahead and click Next. And then finally, click Create bucket. Now once the bucket is created, go ahead and click on it there. And then click the Upload button. From here I'll just click Add files. And then I'll go ahead and browse to where the index. html file is, again, that is in the course exercise files for your convenience. Open that, I'll click Next. Scroll down a bit and under manage public permissions, we will select grant public read access to this object, and again, it gives us that scary little warning. Next. We're not concerned with any encryption here, so click Next again. And then finally click Upload. Now go ahead and click on the Properties tab up at the top, and then over here where it says static website hosting, go ahead and click that box right there and we want to use this bucket to host a website. The index document is going to be the very obvious index. html. We're not going to use an error document or any redirection rules. Click Save. Alright, awesome, looking good. Now let's jump back over to Route 53. Let's go over to hosted zones. Open up the zone. Now let's scroll down and look for the west record that is pointing to web2-west. So here we go, right here. Looks good. Now under the alias target, I want to back over all this, that sounds terrible, doesn't it? I'm going to backspace over all this, span this out a little bit, and for the alias target I want to type a rather long string here, s3-website-us-west-1. amazonaws. com. S3-website-us-west-1, well that's a reference to the region that we created the bucket in. Now you'll notice that this did not pop up in the dropdown. It actually will eventually show up, but for now I'm just going to type it in manually. Alright everything else here looks good. Let's scroll down. Associate with health check, we need to set that to no, because obviously we are no longer checking an instance here, we actually just want this record to go straight to that bucket. Save Record Set. Okay let's go take a look and make sure this all looks good. Yes, there we go. What should happen is when we browse to www. benpiper. host, we should see a static web page. Will it work? And there we go. All servers are down. Please try again later. That's much better than a generic error page, isn't it?

Summary
Thanks for sticking with me through another module. I hope you're starting to see the power and flexibility of Route 53. Health checks and failover records let you route around failures without having to rely on a load balancer or some internal application logic. Implementing failover records, especially when you have more than two, can be complicated. I find that drawing diagrams and tables can help a lot. A flat list of resource records is not the most intuitive way to visualize a nested hierarchy, which is exactly what failover records give you. Something to keep in mind, particularly if your instances are under powered, is that health checks can be intense. If you stick with the defaults, every instance will get checked every 2 to 3 seconds. That could seriously affect the performance of a small instance. Therefore, you may want to reduce that frequency by removing some health checker regions when you're initially setting up your health checks. One apparent downside of failover records is that they don't do load balancing. The primary record gets all the traffic, unless it fails. Well, in the next module we're going to get around that little limitation by creating some weighted records, which do let you achieve load balancing at the DNS level. What's more is you can combine these with your existing failover records to get the best of both worlds. That's coming up next.

Distributing Traffic with Weighted Records
Module Introduction
Welcome back. In this module, you'll learn about and configure weighted resource records. Weighted records let you distribute traffic among different resources without using a load balancer. Instead of having one active record and one passive record, as you would with failover records, you can have all of your weighted records active simultaneously. Here's how it works. In the table on the right, there are four records for www. The policy for each of these is weighted. Also, notice that each resource record points to a different target, web1-east, web2-east, and so on. In contrast to the failover records where Route 53 serves only the primary record, weighted records are always active. That means if a client tries to resolve www. benpiper. host, Route 53 may respond with any one of the web instance IP addresses. Which specific IP address Route 53 responds with is determined by the record weights. In the routing policy column, notice the number 25 in parentheses. Twenty five is the weight of each record. If you add up all these values, you get 100 because each record has a value of 25, each record has a 25% chance of getting selected. In other words, which record Route 53 serves up is somewhat random, but that's okay because the idea is to distribute traffic across multiple instances, and by adjusting the weighs, you can control how much traffic each target receives. Before we jump into the demos, if you've been following along and have shut down the web application, please go ahead and bring it back up on each instance. Here's the command to do that and it's the exact same one I showed you in the lab set up. We need the application to be up, so our configured health checks will pass.

Creating Weighted Records - Part 1
In this clip, we're going to jump right into a demo and start configuring some weighted records. The process of creating the records is easy, but testing that everything is working the way you want it can be a bit tricky. In this demo, we're going to start by reducing the TTL values of our existing records to 30 seconds. This is just to speed up the process of testing our records after we create them. We'll then create four weighted records, each with a weight of 25 and each pointing to a different web instance. That gives us a combined weight of 100, so route 53 should serve up each record roughly 25% of the time. Now just to make sure we're all on the same page, here are the records we're going to create. Notice that we're going to use the name www. We actually already have some existing records for the www name, so we'll delete those first. Let's jump over to our hosted zone. First, let's select the boxes next to the existing www records, and there's two right here, and then let's click Delete Record Set. Next we want to make sure that the TTL of all of our records is 30 seconds, so we'll just go to web1-east here, change this one to 30, save the record set. Web2-east, change it to 30 seconds, web1-west, 30 seconds there, and then web2-west, and we'll change that to 30 seconds, and save. Alright now we're ready to create some weighted records. So let's click Create Record Set. Span this out a little bit. For the name, we're going to do wwww, this is going to be a type A IPv4 address. For alias, we want to choose yes, and the alias target here will be web1-east. benpiper. host. Now for the routing policy, we're going to click this and choose weighted, and let's scroll down. Now it gives us an option for weight and a set ID. For the weight, we'll enter 25. Now the set ID is not automatically populated. You remember when we created the failover records, Route 53 populated the set ID for us. Not so here, this has to be unique per record, so we'll put web1-east. For associate with health check, we'll click yes, and then of course, he we want to select web1-east, and then click Create. Notice here it's telling me alias target contains an invalid value. Well if I click here in the field, you can see that the alias target is actually missing the trailing period. I'll go ahead and click that and now let's go ahead and try to create this again, and that works. Alright let's go ahead and create another record set. This one is also going to be www, the alias for this one is going to be web2-east. We'll select the weighted routing policy. The weight here is going to be 25. And the set ID is web2-east. We will associate this with the appropriate health check for web2-east and then click Create. Alright, two more to go. Www, I'm going to go through this one a little faster this time. Web1-west, the routing policy is weighted, and then this also will have a weight of 25. Enter the set ID and select the correct health check. And finally, one more, alias yes, web2-west is the one we want. The routing policy is weighted. Twenty five for the weight and then a unique set ID, and finally, the health check. And then click Create. Okay, all four of our weighted records here are created, one, two, three four. Now let's jump over to the command line. We'll do an nslookup www. benpiper. host. Notice that it resolves to the IP address of web2-east. Now if I go ahead and run this query again, I get the same response. Why? Well it's because of the TTL, which is 30 seconds. My DNS server is hanging onto that record until the TTL expires. So let's go ahead and wait 30 seconds and then try it again. And we get the same record, which is perfectly fine. Remember that the record Route 53 responds with is going to be somewhat random, that is, it's not going to sequentially bounce form one record to the next in a round robin fashion. However, that does make it harder to validate that your configuration is working. So to help with that, we're going to take a different approach. Let's open up our web browser.

Creating Weighted Records - Part 2
I've opened up a new tab in Chrome and we want to browse to dnspropagation. net, that's spelled DNS p-r-o-p-a-g-a-t-i-o-n. net. This is a free service that will query a domain name from different DNS servers all around the globe. So here where it says enter your domain name, I'm going to put www. benpiper. host and then click Start. The value that Route 53 answers with is shown next to each DNS server. Note that our four different instance IP addresses all show up. So it's clear that Route 53 is returning each of the records. So we can be confident we'll get some kind of traffic distribution, but what's not clear is that the waiting itself is working. We could count up how many times each IP address appears, but that's cumbersome and, frankly, ain't nobody got time for that. So guess what? I've created a PowerShell script to help us out and do the work for us. Let's jump back over to PowerShell. The script we're going to run is named dnstest. ps1. This script will perform a series of DNS queries for the domain name we specify and then display the responses along with a tally of those responses. The idea here is that it will show us a distribution of IP addresses so we can tell whether or not waiting is working. And here's how it works. First I'm going to specify the hostname, www. benpiper. host, followed by the primary name server of the zone, which I have conveniently on my clipboard here. Now why the primary name server? Well each time the Route 53 name server receives a query, it will run a process to decide which weighted record to respond with. This means each time the script queries the name server, it may get a different weighted record. If I were to use my local name server or public name server, like Google or open DNS, those name servers would cache the response for 30 seconds and that would skew our results and make them inaccurate. Alright, next we're going to specify the number of iterations and we'll put 8 here. This is how many times the script will run. Eight is a good number here because we have four records, but remember that because of the somewhat random nature of weighted records, issuing four queries does not mean that we'll get four different responses. So by issuing eight queries, there's a better chance that we'll actually get each record at least once. Finally, we'll specify a sleeptime of 1 second. This is how many seconds the script will pause in between queries. There's nothing magical about 1 second, you could put 2 seconds, or even 0, and it would work. Now remember the rationale I just gave you for not using my local name server? It would cache the responses for 30 seconds. Well you could actually still query your local name server and just set the sleeptime here to 30 seconds or a bit more, and that would overcome that TTL issue. But that would also cause the script to run for 4 minutes, and you don't want to wait for 4 minutes. So, just querying the Route 53 name server directly and pausing for 1 second between queries will give us a quick result. Okay, let's run this. The script tells us how many times Route 53 returned each IP address. Notice that the percentages don't match up exactly with the weights we configured. This is normal. A single client querying multiple times will not necessarily get the exact weight distribution you configure. What's the point of it then? Well if we were to run this through more iterations, say 16 iterations, we would get closer to the configured distribution. Let's go ahead and try it. I'll hit the up arrow and I'm going to change the number of iterations from 8 to 16. Notice how we're slowly converging on 25%. We're getting a little bit closer. Alright, what if we double the number of iterations again to 32? Let's try that. I'm actually going to change the sleep time to 0 so we're not waiting as long, and the number of iterations is 32. Alright this looks pretty much identical to what we had before. Let's go ahead and run this one more time. Alright now we're getting very close. And this is a lot like tossing a coin, if you toss it 10 times, you may get heads 4 times and tails 6 times, but the more times you toss it, the closer you'll get to an equal number of heads and tails. The same thing applies here. Each record has an equal probability of getting chosen because they're all of equal weight. But let's say we don't want this behavior. What if we want, for example, the west coast servers to get twice as much traffic as the east coast servers? How will we do that? Let's talk about that.

Uneven Weight Distribution
Uneven weight distribution may sound like an undesirable thing when it comes to an airplane or a boat, but you may want an uneven weight distribution for your instances. You may want one set of very powerful instances to take on twice as much traffic as another set of underpowered instances, or you may want to slowly introduce a new version of your application by sending only a small portion of users to the instance hosting the new version. In this clip, we're going to reconfigure our weighted records so that Route 53 responds with the IP addresses of instances in the west region twice as often as instances in the east region. The goal here being that web1-west and web2-west collectively receive twice as much traffic as web1-east and web2-east. In this case, thinking in terms of percentages can get a little confusing and hard to work with. If we were to use percentages, we'd have to configure Route 53 to resolve to the west coast servers 66% of the time and that would mean each instance's record gets a weight of 33. That's fine, but the east coast servers would also need to get traffic 33% of the time, that would mean giving web1-east and web2-east each a weight of 16. 5, but weights can only be whole numbers, so we could do a weight of 16 for web1 and a weight of 17 for web2. This is not very elegant. Percentages just are not easy to work with in this situation. So instead, we're going to do this. We'll give web1-east and web2-east each a weight of 10. We'll give web1-west and web2-west each a weight of 20. Now it's really obvious that Route 53 should return web1-west's IP address twice as often as it does for web1-east. If we add the weights together, web1-east and web2-east total 20 and web1-west and web2-west total a weight of 40. Again, it's really clear now that the instances in the west region get roughly twice as much traffic as those in the east region. This is much clearer than using percentages, don't you think? Alright, let's jump back over to our hosted zones. Go ahead and locate the www records and locate the one that points to web1-east as an alias. Here it is right here. Now scroll down to the weight and let's change the weight from 25 to 10 and then save this one. Now let's locate the one that has web2-east as the alias and change the weight of this one to 10 and save the record. Now let's go locate the one that has west as its alias, and this one we want to change the weight from 25 to 20 and save the record, and then web2-west, right here, change the weight from 25 to 20 and save the record. Okay easy, easy, easy. By the way, if you scroll to the right here, you can actually see the weights listed right here. And if that's not clean enough for you, you can click the weighted only box right here and it displays only your weighted records, which you can sort by weight. So nice and handy, nice and convenient. Very nice. Alright, let's jump back over to PowerShell and run the DNS test script again. Alright, we're going to go ahead and stick with the same number of iterations, 32 iterations, and a sleep time of 0 seconds. Let's run this, see what we get. It's clear that those two IP addresses in the middle show up about twice as often as the other two, which is exactly the behavior we configured. Something I like to do, just for fun, is bring in my friend the calculator here, and I'll add up those two in the middle, 28. 13 plus 37. 5 and that gives me 65. 63, which is incredibly close to 66. Now if I clear that out and I add up 18. 75 plus 15. 63, I get 34. 38, which again, is incredibly close to 33%.

Health Check Failures
Recall that earlier we configured a health check for each weighted record. Right now all of our web servers are up, but what happens if one of them goes down? Well the short answer, and probably the answer you would expect, is that Route 53 just won't route any traffic to that server. That is, Route 53 won't respond with the IP address of any server that's down. But the part that's not obvious is how that will affect the weights. Let's suppose that the web1-east instance goes down. It's weighted record has a weight of 10, but as soon as the health check fails, Route 53 effectively changes this to 0. It doesn't actually change the value of the weight to 0 in the record, but for all practical purposes, it becomes 0. What that leaves us with is 3 weights, 10, 20, and 20, which add up to 50. Web2-east would get roughly 20% of the traffic, while web1 and web2-west would get about 80% of the traffic. So this gives us a very different distribution than what we started with. That's fine, there's nothing wrong with that, but it may not be what you'd expect. Let's go ahead and bring this scenario to life. In this demo, we'll shut down web1-east and let it fail its health check. We'll then run the dnstest. ps1 script to see how it changes the traffic distribution. Let's jump right over to our SSH session with web1-east. Here we are on web1-east and I'm going to go ahead and do Control+C to break out of the Docker container, and then we'll pause for a minute to let the health check register the instance as unhealthy. Let's go ahead and run the dnstest. ps1 script again. We're going to go ahead and run this against the same host name as before, www. benpiper. host, and 32 iterations. Notice that instead of resolving to four different IP addresses, the domain name only resolves to three this time. The record resolves to web1 and web2-west about 90% of the time and web2-east about 10% of the time. Now let me ask you something, what happens if all of the web instances go down? Well believe it or not, Route 53 treats them exactly as if they are all healthy. I'm not going to demonstrate that because we've already seen how it behaves when all of the web instances are healthy. Again, there's no difference in behavior. If they're all unhealthy, Route 53 treats them as if they are all healthy. Now before moving on, let's go back to web1-east and bring the web application back up. Back in our SSH session with web1-east, I'm just going to hit the up arrow here to get back the docker run command, and I'll hit Enter to let that come back up. Once you've done that, you're good to go.

Combining Weighted and Failover Records
In this clip, I'll show you how to chain together weighted and failover records to get the best of both worlds. Here's what we're going to do. We'll start by renaming the existing www records to weighted, nothing else about these records will change except for the name. We'll keep the same weights and the same targets. We'll then create two failover records. The primary record will point to the weighted alias record set and the secondary will point to the S3 bucket that we created earlier containing the static web page. Here's what this will accomplish. If a client tries to resolve the www record, as long as an of our web instances are up, traffic will go to the ones that are up. However, if all of the web servers go down, then the secondary failover record will kick in and that will route the client to the S3 bucket hosting the static web page. This way a client never encounters a situation where they just get a generic error page. They're either going to hit a web instance or they're going to hit the S3 bucket and see a static web page. Now to reiterate, in this demo, we'll rename the www records to weighted, this is just a straight rename, we won't change anything else about the records. We'll then create a failover record set with the primary record pointing to the weighted group, and the secondary pointing to the S3 bucket. Let's jump over now to our hosted zone. The first thing we'll do is change the name of the existing records to weighted. So I'll go ahead and select the first one here, click the little pencil icon and then change this from www to weighted, save the record set. And we're just going to go ahead and run through this real quick and change each record. All of them have been renamed. Now we will create the primary failover record. Click Create Record Set. The name here is going to be www. benpiper. host. This is going to be an alias record and the alias target is going to be the weighted record set. There we go. Alright let's scroll down to the routing policy and we're going to choose failover, and again, this is going to be the primary record set. The set ID is fine. Now this time, we're going to set evaluate target health to yes because the target itself is a weighted record set that is being health checked. As long as any weighted record is healthy, Route 53 will consider the target itself to be healthy. We can stick with no for the health check, and then click Create. Next, we're going to create the secondary failover record pointing to the S3 bucket. Click Create Record Set, www, this is going to be an alias record, and you can see that the S3 bucket endpoint has finally showed up. You may remember from an earlier module that it did not show up in the list, but I said given enough time, it will eventually show up, and here it is. So we can just go ahead and click on this and it fills it in for us. Let's scroll down to routing policy. This is going to be a failover record set and we want to make this the secondary record, and here we're going to set evaluate target health and associate with health check to no. Incidentally, you don't ever have to evaluate target health or set a health check on a secondary record. You can, in case you ever decide to swap the primary and secondary records, but you don't have to. Alright, let's go ahead and click Create here. I'm going to click the Aliases Only box up here so we can view only these records. And there we have our primary record pointing to the weighted set, our secondary record pointing to the bucket, and then of course our weighted record sets, four of them here pointing to each of our instances. Perfect. Let's jump over to PowerShell. We're going to go ahead and run the dnstest script again, using the same parameters. And this looks very similar to what we saw before, the distribution roughly corresponds to the configured weights. Now what happens if all of the servers go down? Remember that before Route 53 would treat them all as healthy if they went down. But now that those weighted records are subsidiary to a failover record set and Route 53 is evaluating the health of those weighted records, what will happen? Well let's go ahead and shut down all of the servers again. To save time, I'll do this behind the scenes and if you're following along, feel free to do the same. Now that all of the instances are shut down and have failed their health checks, we want to run the dnstest script again, but this time we're going to do only 4 iterations instead of 32. So I'll put 4 here and then let's run it. Wow, do you recognize any of these IPs? These are not our elastic IPs. In fact, these belong to S3. Take a look. We'll search the current list of S3 IP addresses using the command get-AWSPublicIpAddressRange, ServiceKey is going to be S3, the region us-west-1, and I want to show only the records matching, we'll pick the first IP address, 54. 231 is what it starts with. And yes indeed that IP address is in this particular subnet showing up here, which does belong to the S3 service. So this looks promising. Let's see what we get when we browse to the site. We'll go to www. benpiper. host, and bingo, we hit the static web page. Perfect. Alright, before moving on, I'm going to bring the web servers back up, again, to save time I'll do this behind the scenes. If you're following along, please go ahead and do likewise.

Summary
Weighted records let you distribute traffic across your resources according to the weights that you set. You can use any weight between 0 and 255 inclusive. A weight of 0 effectively removes the record from distribution, unless, of course, all records in the set have a weight of 0, in which case they are all treated equally. The reason behind this is so that you don't accidentally disable all of the records in your set. If you assign a health check to a record and the health check shows unhealthy, or if you're evaluating the target health and the target is unhealthy, then Route 53 effectively disables that record and does not consider its weight. Route 53 treats that record as though the weight were 0. Last but not least, weighted records and failover records can be chained together, as we did in this module. Alright, that is it for weighted records. In the next module, we're going to cover geolocation and latency records.

Geolocation and Latency Records
Module Introduction
Welcome back DNS lovers. In this module, we're going to cover two different, but related, resource record types, geolocation records and latency records. Before we jump in, I want to stress that the global nature of the internet's domain name system makes every Route 53 configuration very unique. That does present a bit of challenge when you're following along with the labs because you're not using the same domain name I am, and you're not in the same location I am. So some of the labs that I show in this course will necessarily differ, in some cases quite drastically, from what you might experience. This is especially true when dealing with geolocation and latency records. Now it's time for a geography lesson. To illustrate how these record types work, I'm going to use the United States because, yes, that's where I live, but also because US locations in Route 53 are treated a bit differently than other countries, as we'll see in a moment. The United States is, of course, divided up into 50 states, all shown on this map. There are three of these states that I want to draw your attention to. Over on the left, or west side of the map, that big orange state is California, which is where the us-west-1 AWS region is. Over on the right, the east side of the map, the orange state is Virginia. That's where the us-east-1 region is. Two states south of that, you've got the state of South Carolina, which is where I am. Throughout the module I'm going to refer to South Carolina by its state abbreviate, SC. Okay, that's your geography lesson. Now it's time for a lesson on geolocation records.

Creating Geolocation Records - Part 1
Geolocation records lets you route traffic to resources based on the location the DNS query originated from. That's pretty simple. And yet, geolocation records are quite possibly the most misunderstood record type in the Route 53 arsenal. To understand why, let's take a look at some examples. I have two geolocation records listed here. The top one has the United States listed as the location and web1-west is the target. The record directly underneath has the US state of South Carolina listed as the location and web1-east is the target. The locations here refer to the source of the DNS query. Over there on the left we have a client, this is a client in the usual sense of the word, it's someone who's trying to access one of our web servers. As we discussed before, the client uses a DNS server. That DNS server could be on the client's local network, as would be the case in an organizational environment or a home network. It's also possible that the DNS server is some public DNS server, like Google or open DNS, and it's not local to the client. Now, let's say that the client tries to browse to www. benpiper. host. It's going to reach out to its DNS server to resolve that address and the DNS server will use recursion to get to the Route 53 name service and ask for the record for www. benpiper. host. Again, this is the exact process we cover at the very beginning of the course. The question is, which of these two geolocation records will it get? Well, that depends on the location of the DNS server. If the DNS server is in South Carolina, then Route 53 will return the geolocation record that has South Carolina listed in its location. That record points to web1-east, so the client connects to that instance. Ah, you might wonder, but why doesn't Route 53 choose the first record, which has United States as the location? It's because route 53 will choose the most specific record. Okay, that's pretty intuitive, but here's what's not so intuitive. This time, suppose that the client's DNS server is in Virginia, what record will it receive from Route 53? It will receive the record with only the United States listed as the location because Virginia is in the United States. Even though there's no specific record for the states of Virginia, there is a specific record for the United States, and Virginia is in the US. But you might wonder, isn't Virginia close to South Carolina? Yes it is. So why doesn't Route 53 serve the record with South Carolina as the location? Well, it's because the location has to exactly match the location the query came from. In this case, the query did not come from South Carolina. The geolocation record matching the United States is the most specific record. When it comes to geolocation records, close does not count. Alright, one more example and then we're going to jump into the demo. Suppose now that the client's DNS server is in Germany, which resource record will it receive? The answer is none of these, instead it will get a nonexistent domain error. Germany is not in the United States. None of the geolocation records match Germany, or even Europe. What we need here is a default record that will catch anything that doesn't match one of the more specific records, and voila, here's what it looks like. The default record points to web1-east. Now it could just the same point to an S3 bucket or another instance, but to keep this already complex topic from becoming more complex, we'll leave it like this. Now when the DNS server in Germany tries to resolve www. benpiper. host, Route 53 will serve up the record matching the default location and that record points to web1-east. Now we have something useable.

Creating Geolocation Records - Part 2
And now it's time for the demo. We're going to create the geolocation records I just showed you in the diagram, and then we're going to test by initiating queries from DNS servers around the world. Let's go to our hosted zone. We're going to start by deleting the existing www records. I'll go ahead and select the box next to each record, Delete Record Set, and Confirm. Okay whoosh. Those are gone. Now we are going to create a record set, the name of this is going to be www, it is a type A record, for alias we'll select yes. Now the alias we want to select here is web1-west. There we go, web1-west, and of course, got to click and make sure we actually get the full name in there, and let's scroll down to the routing policy, and under here we are going to select geolocation. Let's scroll down a bit more. Now say that it gives us a location dropdown box, if I click it, I get a long list of locations. There are continents, and if I scroll down two clicks, there are countries also. Now here I will type in United States and select the United States. And notice here that it adds a sublocation. If I click the dropdown, I'm presented with a list of states, as well as the District of Columbia. Now for this record, I'm just going to leave the sublocation empty. For the set ID, I'm going to put www-usa. For evaluate target health, we will leave that as no. And associate with health check, we'll choose yes and we will associate this with web1-west. There we go, and now we create this record and now we're going to create another record. This will also be named www, this time the alias we're going to choose is web1-east. benpiper. host. The routing policy is geolocation. Now for the location, I am, again, going to type in United States so that I can get this sublocation dropdown. And from here, I want South Carolina. So I click South Carolina, and there we go, and for the set ID, www-usa-sc, again, sc for South Carolina. Evaluate target health is no, and associate with health check will be yes. And we want to use the health check for web1-east. Excellent. Let's click Create. Okay. Now if you please, scroll to the right until you see the geolocation header, and let's scroll down, there we go. There we can see the locations for the records we just created. US and then US with SC, South Carolina, in parentheses. Now let's open up another tab in Chrome and let's browse to www. benpiper. host. And here we hit web1-east. Remember that the record that has the South Carolina location is pointing to web1-east as its alias. I'm getting this record because my DNS server is in South Carolina. The query to Route 53 is originating from South Carolina. But what if the query comes from somewhere else, let's say it's a different state or a different country? Well let's open up another tab and go to dnspropagation. net, and here we'll simply enter www. benpiper. host and start the query. The DNS server in Dallas, Texas resolves to 54. 219. 0. 218, which is web1-west. Dallas is in the US, but it's not in South Carolina. So Route 53 responded with the record for the United States location. Notice that none of the DNS servers outside of the United States got a response. They all show timeout. This is because there's no record matching their locations. Let's jump back over to our hosted zone. Recall from the example I gave earlier that we can use a default record to catch any locations that we don't have specific records for. So let's go ahead and create a default record. Create Record Set, www, now for the alias here, let's choose web2-west because that's different than any of the others we've been using. Routing policy, geolocation. And if I click the location, notice that the very first option is default, so we click default. And for the set ID, www-default. Alright, so we will go ahead and associate this with a health check and this is web2-west, so we'll click Create. Super. Alright, let's scroll down here and we can see here that for the geolocation we have an asterisk for the location indicating the default location. Now let's jump back to the DNS propagation tool and let's rerun this. Now we're still getting a few timeouts here, and I'm guessing that that has something to do with the negative caching TTL. Let's wait a few seconds and run this again. Now at least some of the queries from outside of the United States resolve to 54. 177. 105. 227, which is web2-west. You can see from this that when it comes to geolocation records, Route 53 does not consider the proximity of a querier to the location. The location of the querier must exactly match the location in the record or Route 53 will not serve that record. Okay let's jump back over to our hosted zone. In preparation for the next demo, we're going to go ahead and delete all of the geolocation records. So let's go ahead and find those, one, two, three. Those are all of them. Delete. Confirm. And they're gone.

Creating Latency Records
Latency records offer a way to improve the client experience by sending the client to the resource with the lowest network latency. Unlike geolocation records, when it comes to latency records, being geographically close to a resource does count. Earlier we established that South Carolina is much closer to Virginia than it is to California. Why does that matter? Well as a general rule, the closer two sites are geographically, the less network latency there is between them. That's not always the case, but if we know nothing else, other than the geographical distance between sites, then that distance is usually going to be a pretty good indicator of latency. So at least theoretically, my latency to Virginia should be lower than my latency to California because, again, South Carolina is geographically closer to Virginia. Now here's why that matters. Consider please the two latency records at the top of the table. The first record uses a latency routing policy that lists us-east-1 as the AWS region. Again, us-east-1 is in Virginia, on the East Coast. This record points to web-1-east as its alias target. The next record down also uses a latency routing policy that lists us-west-1 as the AWS region, that region is in California, on the West Coast. This record points to web1-west as its target. Suppose now that my DNS server, sitting here in South Carolina, tries to resolve www. benpiper. host, which record will it get? Well, that depends on the network latency between South Carolina and the two AWS regions I just mentioned, most likely the latency between South Carolina and Virginia will be less. In that case, I would get the record with the us-east-1 region, which points to web1-east. Okay let's take another example. Suppose instead that the DNS server making the query were in California. Well the latency from anywhere in California to the us-west-1 region, which is also in California, is going to be considerably less than the latency between the DNS server in California and the us-east-1 region in Virginia. Chances are, the DNS server would get the record with the us-west-1 region, which points to web1-west as the target. Let's go see this in action. In this demo, we'll create two latency records, one that considers latency to the us-east-1 region and another that considers latency to the us-west-1 region. We'll then see which of these two records Route 53 gives me. Let's jump over to the hosted zone. First things first, let's create a record set, www. The alias here is going to be web1-east. And for the routing policy we will, of course, choose latency. And under region, we're going to select the us-east-1 region. There we go. Now the set ID, I'm going to go ahead and call this usa-va, va being the abbreviation for Virginia, which is where the us-east-1 region is. And we will associate the health check belonging to web-1-east, and then Create. That was easy enough, right? Alright let's create another one, www, this one is going to be pointing to web1-west, and this is a latency routing policy. The region here is us-west-1, right here, very first one. And the set ID, usa-ca and web1-west for the health check. And then Create. Okay, I'm going to go ahead and open another tab here and let's browse to the site. It looks like we get web1-east, and that makes sense because my DNS server is geographically closer to Virginia than it is to California and geographic proximity tends to mean lower latency. But what about other locations? Let's go visit our old pal, the DNS propagation checker. We've already got it open in the tab and it's already populated with the domain name, so we'll just go ahead and click Start. Now let me scroll down a bit so that we can see all of these. Note that most of these resolve to web1-east, but some resolve to web1-west. It's clear that there is not an even distribution here. It's really more like a 4 to 1 in favor of the us-east-1 region. Now if you scroll down some more, you'll see there is a nice map that shows us where each of these serves is located. If I hover over Vancouver, Canada, notice that it resolves to 52. 206. 88. 55, which is web1-east. Now if I hover over Montreal, well we get a timeout. So for some reason that just did not work. So this just could be an issue with the DNS propagation checker service. Let's go ahead and run this again just to make sure, and let's go ahead and scroll down again, and we still have a timeout for Montreal. Well let's pick a different one. How about, ah Mountain View, California. Alright, this also resolves to web1-east. Now if you're in California, your latency to the us-west-1 region in California should be much lower than your latency to Virginia. But alas, that does not appear to be the case. And this is a very good lesson, latency changes all the time. That means that the results you see here will change sometimes minute to minute, and it is also very unpredictable. Let's look down here in South America, Peru. This also points to web1-east. Well, gee, I mean, do any of these point to web1-west? Well it looks like Australia does resolve over to web1-west, but for the most part, most of these resolve to the AWS Virginia region. And I'll be honest with you, that is not what I was expecting and it's probably not what you were expecting either. Alright, let's jump back over to our resource records. Now in preparation for a later demo, we're going to go ahead and remove all of our records that have alias targets. I'm going to click the Aliases Only box here and then I'm going to select this box up here at the top to select all the records, and then I'll click Delete Record Set. I'm deleting 10 records here, Confirm, and they are all gone.

Summary
Geolocation and latency records are dependent upon geography to one degree or another. The use cases for each, however, are very different. Geolocation records are useful when you want to route traffic to a resource based on the specific geographic location the query came from. For example, if the user is in the United States, you may want to route them to resources in one of the US based AWS regions. If they're in South America, you may want to route them to the region in Brazil. Remember to create a record for the default location to catch any locations you haven't explicitly specified in your other records. If you don't specify a default location, anyone outside of the locations you have specified will get a nonexistent domain error. Remember, when it comes to geolocation, close does not count. Latency records will route traffic based on the network latency between the location of the query and the specific region listed in the resource record. Unlike geography, which is fairly static, network latency changes constantly. This can give you some pretty interesting and unexpected results, as we saw a moment ago. Up to this point, we've been creating records manually. But in the next module, I'm going to show you how traffic flow policies can do the hard work for you. Traffic flow policies also let you create geoproximity records, which are like geolocation records, except they don't require you to specify a geographic location. That's coming up next.

Creating Traffic Flow Policies
Module Introduction
In this module, you're going to learn how to create traffic flow policies. This is going to be a short module because the process for this is easy. In fact, if you were to use just one word to describe traffic flow policies, that would be it, easy. There are two components to the traffic flow architecture. First, there's the traffic flow visual editor. This is a drag and drop GUI that lets you create and chain together resource records by linking them together in a graph, rather than having to do it by hand. The traffic flow visual editor generates a traffic policy, which is just a text document in JavaScript Object Notation, or JSON, format. You can then install this policy in your zone as a policy record. This sounds really easy, why didn't we just use this to start with? Well it comes at a price, $50 US per policy record per month. Yikes. Now my experience has been that when I've created a policy record in a zone and deleted it within a few hours, I have not been charged. However, please don't assume that you will get the same treatment. AWS does not claim that you won't be charged and neither do I.

Creating Traffic Flow Policies
It's my speculation that the cost of a policy record is driven by the fact that it offers one routing policy that you cannot get any other way, and that's the geoproximity routing policy. The geoproximity routing policy lets you route based on geographic proximity to an AWS region. This is in contrast to geolocation policies, which route based on being in a geographic location. In this demo, I'm going to show you the traffic flow visual editor. We'll use it to create a geoproximity record within a simple traffic policy. Because of the cost associated with creating the policy record, I'm not going to create one because I don't want you to inadvertently incur those charges, but I will show you how to get to the step just before that so you can make the decision for yourself. Let's jump back over to the Route 53 dashboard. Here at the dashboard, go down on the left side menu to traffic policies. Welcome to Traffic Flow. Here click the Create traffic policy button. And under policy name, I'm just going to call this one geoproximity routing. Notice that this places us at version 1. AWS automatically versions these so that over time you can track your changes and, of course, revert back to an old version if you need to. We'll leave the description blank and click Next. Now here it gives us a nice GUI with a background that reminds me of graphing paper. In the starting point, if you click the DNS type dropdown, you can see all of the record types that you can create. We'll create an A record and then we'll click the connect to link, and let me scroll down a little bit here. Now this is where you can choose your routing policy. These look familiar, don't they? But one that's new is the geoproximity rule. Hmm, let's click that. And now here it lets us choose an endpoint location. You can either enter custom coordinates here, or you can click the dropdown and select an AWS region. I'm going to choose US East in Northern Virginia. Now the bias setting we'll get to in a second because it makes more sense when you have two of these records. For now, go ahead and expand health checks and we will select the web1-east health check. Scroll back up a little bit. Now what should this record resolve to? Well it should resolve to web1-east, so let's go ahead and click Connect to. Scroll down a little bit. Here you can choose a different routing policy, so you can chain these together. But notice what's missing here. There's no option for an alias record. Instead we only have an option to create a new endpoint. So let's click that. Scroll up a little bit. Let's go ahead and click the type dropdown and we get different options. We've got CloudFront distribution, Elastic Beanstalk, ELB Application load balancer, and so on. But we still don't have an option to choose an existing record. So instead, we'll have to simply choose value. For the value here, we will enter 52. 206. 88. 55, which is web1-east. Alright, now let's scroll down here and we'll go through the same process, under the endpoint location we are going to choose US West in Northern California and for the health check we will choose web1-west. Alright, for the endpoint, we'll go ahead and do connect to, new endpoint, and then the value I'm going to enter here is going to be web1-west's elastic IP, 54. 219. 0. 218. Alright now we'll scroll back up a little more here. If a DNS server is closer to the US East region, then Route 53 will answer with the IP address of 52. 206. 88. 55. However, if a DNS server is closer to the US West region than the US East region, Route 53 will answer with the IP address 54. 219. 0. 218, which is web1-west. The bias record in each of these records either drives more traffic to a given record or more traffic away from a given record. If you increase the bias value, Route 53 will answer more queries with this record. If you decrease the bias value, it will answer fewer queries with this record. This is extremely valuable when you want to achieve a particular distribution of traffic, it's literally as easy as sliding this slider. Okay, let's go ahead and create this traffic policy. We'll go ahead and click the Create traffic policy button down at the bottom right. And it says successfully created traffic policy using geoproximity routing, that's the name of the policy, version 1. Now be very careful here. It gives you the option to create a policy record in your hosted zone. If you wanted to do this, you could enter www under the DNS name, set the TTL, and then if you're okay with paying $50 USD a month, you could click the Create policy record button at the bottom. I'm not going to do that. I'm going to click skip this step. And there's my traffic policy. Now note that AWS does not charge you for simply having a policy, that part is free. It's the policy record that costs you. However, if you like to keep a clean house, you can click the box next to the record and then click Delete policy version, and then click Delete, and it's gone. And that's it.

Summary
See, I told you this would be a short module. The traffic flow visual editor makes it easy to create and chain together different resource types to generate traffic policies. You can then use that traffic policy to create a policy record in your hosted zone. This is not free and it's not included with any other pricing. As of now, $50 US per record, per month is the cost. But it might be worth it to you, especially if you need geoproximity routing, which is currently only available via traffic policies. Well that's it for traffic flow policies. In the next module, you'll learn how to achieve load balancing using multivalue answer records.

Load Balancing with Multivalue Answer Records
Module Introduction
Hello again and welcome back. In this module, you're going to explore multivalue answer records. Every resource record we've created so far returns only one IP address in the resource data. Multivalue answer records, as the name suggests, return multiple IP addresses in a single answer. By returning multiple IP addresses in a single answer, the client can decide which of those IP addresses to use. Generally the client will choose the first IP address in the list, but it's free to use the other addresses as well, for example, if the client can't connect to the first IP address in the list, it can try the second, and so on. Something we have not done, though it is possible, is create a simple resource record with multiple IP addresses. This also results in a client getting back multiple IP addresses in a single answer and thus being able to choose among those addresses. However, the advantage of multivalue answer records is that you can use health checks with them. This means if an endpoint fails its health check, Route 53 will remove its IP address from the answer that it returns to the client.

Creating Multivalue Answer Records
As I mentioned, multivalue answer records are very similar to simple resource records and they are almost just as easy to configure. As with most things DNS related, this is easier to understand if you see it. In this clip, we're going to create four multivalue answer records. The thing to keep in mind is that even though we're creating four records, the answer that Route 53 returns will contain all of the IP addresses in our instances. That is, of course, unless one of those instances fails the health check, in which case Route 53 will remove that instance's IP from the list. Are you ready for another demo? Of course you are. As I said, we'll create four multivalue answer records, we'll then confirm that Route 53 answers with the IP addresses of all four instances. We'll then bring down the web application on web1-east and see if Route 53 removes its IP address from the list of answers. Let's jump over again to our hosted zone. As always, we're going to start by creating a record set. We'll stick with the name that we've been working with this whole time, which is www. But we're going to do something a little different this time. In this case, we're not going to select an alias. Instead, we are going to populate the value with the IP address of web1-east, which I have conveniently on my clipboard. For the TTL, we're going to go ahead and leave that at 5 minutes or 300 seconds, and for the routing policy, we will select multivalue answer. Now here under the set ID, we're just going to go ahead and call this web1-east, this makes it easy to identify what the target is. And then for associate with health check, we want to select yes, web1-east. Now notice that it gives us a little warning symbol here. Hmm, what is this about. We recommend you specify a TLL of 60 seconds or less. Okay, well you know what? I'm going to purposely ignore that for now. We'll deal with that in just a moment. But for now, let's go ahead and create this record, and then let's create another one. Www, we'll go ahead and pop in the IP address of web2-east, multivalue answer, and I'm going to name the set web2-east, and we, of course, will associate this with the health check for web2-east. Create another record set, www, and I'm going to run through this rather quickly, so you don't have to just sit there and watch me type, web1-west, and associate with the health check for web1-west and then create the record. Okay, now for this last record, I'm going to do something a little bit differently. Create Record Set, of course we're going to stick with the same name, www, I'm going to paste in the IP address of web2-west, I'm also going to select multivalue answer. I'm going to set the set ID to web2-west and I'm also going to associate this with the web2-west health check. So what am I going to do differently here? Well, let's go take a look at the TTL here. Recall that in the first three records, we set the TTL to 300 seconds, or 5 minutes, and Route 53 complained about that. It let us do it, but it warned us that we probably should choose a TTL of 60 seconds. So let's head that little warning and change this one to 60. Now what's going to happen here is that once I create this record, Route 53 is going to lower the TTL of the other records to match. It'll take the TTL of the last record you create and it will change the value of the other records in the set. Let's go ahead and click Create. Now let's go ahead, locate these records, and let's look for the TTL header here. Alright, there it is. So those records are at the very bottom. There we go. Notice that they're all 60 because that last record we created had a TTL of 60. So even though on the first three we had a TTL of 300 seconds, on that very last one, we set it to 60, which is what Route 53 recommends, and it thus changed all the other ones to 60 seconds. Very convenient, very thoughtful. Now remember that I said the difference between a simple resource record and a multivalue answer record is that you cannot set health checks on simple resource records. But you don't have to take my word for it, let me show you. Let's create another record set. I'm going to go ahead and name this one simple, and here I'm going to do something I have not done in this course, and I'm going to go ahead and paste in all of the IP addresses of all of our web instances, each one on a different line. This is perfectly valid, in fact this is a normal way to do it. However, notice that we get no option to set a health check, it's just not there. Let's go ahead and save this and then once we save it, let's jump over to PowerShell. Let's start by querying for the multivalue answer record. We'll do nslookup www. benpiper. host, and the Route 53 name server. Notice that we get four responses, which appear to be in random order. Now this is different than the other record types for Route 53 returns only one address. Let's go ahead and run this one again. This time we get the same addresses, but in a different order. And yes, this order is random, or at least sudo random. Now let's compare this to the simple record set we just created. We'll go ahead and query for simple, and here's our list of IP addresses, let's go ahead and run this again and we get the same IP addresses, but again, this also seems to be in a random order. So again, the difference here between simple resource records and multivalue answer records is the health check. So let's see what happens when we shut down web1-east. Let's jump over to an SSH session with web1-east. Alright, I've got web1-east up here and I'm just going to go ahead and do Control+C to break out of the Docker container, and once this goes down, we'll wait about a minute to let the health check fail. Just for a change of pace, I've come back over here to the health checks dashboard, so that we can see that web1-east has in fact failed its check and it is very sick, it's unhealthy. Alright, let's go ahead and run those queries again. We're going to go ahead and start by running the query against www, and notice we get only three IP addresses now. What's missing? The IP address of web1-east because it failed its health check. Now let's contrast this with the simple resource record. We still get all four records, even though web1-east, who's IP address is the one ending in 88. 55, is down. By this point, you probably know what question I'm going to ask next. What happens if all of the web servers go down? Yes, that's right, Route 53 will treat them all as healthy and it will respond with all of the records. You've seen this behavior before, earlier in the course, so I'm not going to demonstrate it here, it's pretty consistent across the board. But feel free to try it out for yourself.

Summary
Multivalue answer records are almost exactly like simple resource records in that they're simple. Both will respond with multiple IP addresses. The key difference is that only multivalue answer records will let you use health checks to avoid responding with the IP address of an instance that's down. When creating multivalue answer records for a domain name, the TTL of the last record you create will overwrite the TTLs of the other records in the set. In other words, the last TTL wins. Well, that is it for multivalue answer records. In the next module, we're going to shift gears and look at creating private hosted zones that are only resolvable within Amazon VPCs. See you there.

Creating Private Hosted Zones for Amazon VPCs
Module Introduction
In this module you'll learn how to create and use private hosted zones. But first, let's talk about why you would use a private hosted zone to begin with. First, in contrast to a public hosted zone, which is resolvable by anyone on the public internet, private hosted zones are resolvable only by resources within the VPCs that are associated with the zone. This means you can use any domain name you want, even if it's already a domain name that's in use on the public internet. This is useful if you want your instances to resolve a certain domain name to one IP address while having users on the internet resolve the same domain name to a different IP address. This is often called split-brain DNS. Here's what we're going to be building in this module. We're going to create a private hosted zone for benpiper. host. This zone is completely separate from the public hosted zone with the same name. We're going to associate this hosted zone with our two VPCs in the us-east-1 and us-west-1 AWS regions. For clarity, I'm showing the region names instead of the VPC names, but just remember that you associate a private hosted zone with a VPC, not with a region. In this zone, we're going to create a simple record named db, which will point to the private internal IP address of the db-east instance in the us-east-1 region. We're also going to create a VPC peering connection between our two regions. We'll reconfigure a couple of our web servers to try to connect to the db-east instance using the domain name db. benpiper. host. This is actually just a simulated database connection, there's not going to be any actual database running on db-east. The web instances are just going to be trying to make a TCP connection to it on port 22 as a way of simulating a database connection. Okay, we've got a lot to do here, so let's jump right in.

Creating Private Hosted Zones
Up to this point we've been running nslookup from a local client machine. But now that we'll be dealing with private hosted zones, we'll be running nslookup from within our instances. In preparation for that, please go ahead and open up an SSH connection to web1-east and web1-west. In this demo, we'll reconfigure web1-east to point to db. benpiper. host for the simulated database connection. We'll create a private hosted zone and associate it with the VPC in the us-east-1 region. In that zone, we'll create the record for db. benpiper. host. Let's jump over to the list of hosted zones. Here in the list of hosted zones, click the Create Hosted Zone button and in the domain name we'll put benpiper. host. Again, the domain name can be the same as a public hosted zone. For the comment, we'll do private - east, west, and the type is, of course, going to be private hosted zone for Amazon VPC. Now here it gives us the option to choose a VPC ID. If I scroll down here until I see Northern Virginia, notice that it gives you a list of all the VPCs across all the regions. Let's start by selecting the r53-lab-vpc in Northern Virginia. And it says to use private hosted zones, you must enable DNS host names and DNS support. We actually did this as part of the lab setup at the beginning of the course, so we're good here. Let's go ahead and click Create. And immediately it takes us to the hosted zone. Now take a look at the name servers here. I've noticed that every time I've created a private hosted zone, Route 53 assigns these same name servers, but what's even more interesting is the numbers. If you're familiar with binary math, you'll recognize the numbers 512, and 1024 as being 2 to the 9th and 2 to the 10th power, respectively. And 1536 is the number for the RFC document that covers common DNS implementation errors. So it looks like someone at Amazon got creative in selecting these name servers and has a sense of humor. Anyway, we don't need to know what these name servers are because we don't have to update any registrar in order to use a private hosted zone. Let's go ahead and click on hosted zones. We've got two hosted zones with the same name, one public and one private. Now to refresh your memory, let's jump into the public zone and let's scroll down until we can see our simple records, all the way down here. We've got records for www, web1-east, web1-west, and so on. Now keep that in mind and let's jump into our SSH session with web1-east. Now if I do an nslookup www. benpiper. host, look what happens. The server can't find it, nonexistent domain, that's what NXDOMAIN means. But we just saw this domain name in our public hosted zone, right. So why isn't it resolving? Well let's do an nslookup -type=ns benpiper. host. These are the name servers for the private hosted zone. We can't resolve www. benpiper. host because that record doesn't exist in the private zone, it only exists in the public zone. This instance, which is in the VPC associated with the private zone, does not have any way of resolving records in the public hosted zone for benpiper. host. Notice, by the way, that we can resolve other domain names on the internet, for example, Pluralsight. com. Now this is why people often call this setup split-brain DNS. Okay, let's go ahead and reconfigure the web server to point to db. benpiper. host. The command for this is very similar to what we ran in the lab set up, sudo docker run --rm -p 80:80, and we're going to add a -e DBHOSTNAME=db. benpiper. host, that's the domain name of the database server, and then benpiper/r53-ec2-web. Alright once you have that typed in there real good, go ahead and hit Enter and while that's loading, let's go back to our private hosted zone. We'll click on the private hosted zone here, and in here let's go ahead and click Create Record Set. Under name we'll do db. This is going to be an A record, and for the value we'll put 172. 3. 1. 100. Again, this is the private IP address of db-east. We'll stick with a simple resource record, but notice that if you click in the dropdown, it gives us all the same options as in the public hosted zones. However, not all of these options will work, for example, you may create a geolocation record in a private zone, but officially it's unsupported, although you're welcome to experiment with that if you want. Alright, sticking with the simple record, let's go ahead and click Create. And it will take about a minute, maybe longer, for the instance to pick up the new record. Let's go and open up another tab here in Chrome and let's type web1-east. benpiper. host. The database domain name shows db. benpiper. host, the database IP shows resolution failed. Again, like I said, it takes about a minute for the change to take effect. Let's go and hit reload here. And now the database IP shows 172. 3. 1. 100. The status, however, shows not connected and that's just because the security group is not configured to allow the connection. That's fine because all we care about for the moment is name resolution, which is working great.

Associating Additional VPCs with Private Hosted Zones
In this clip, we're going to expand our scenario to include the west region. Now to do that, we'll need to do two things. We'll associate the VPC in the us-west-1 region with the private hosted zone. We'll also reconfigure web-1-west to try to connect to db. benpiper. host. Let's jump over now to our SSH session with web-1-west. These look so similar, I know, but this is web-1-west, and we're going to go ahead and stop the Docker container by doing a Control+C. Once it stops, let's do an nslookup db. benpiper. host, and as expected it says nonexistent domain name because that domain name does not exist in the public hosted zone, and we have not yet linked the private hosted zone to the VPC that web-1-west is in. Now if I do an nslookup www. benpiper. host, this does resolve from the public hosted zone, and in fact, you can see we're getting our multivalue answer records. Alright, let's jump over then to our list of zones and I'll show you how to link the private zone up to this VPC. In our list of hosted zones, click the radial button next to the private zone, right here, and observe on the right that we have one associated VPC. To associate the west VPC, we'll go ahead and click in the field here, and then we'll scroll down until we see Northern California, right here, and we will select the r53-lab-vpc. And then scroll down here and we will click Associate New VPC. And there we go, both VPCs are associated with the private zone. Just as before, we'll need to wait about a minute for the changes to take effect. Let's go ahead and jump back to our SSH session with web-1-west. Let's try again to resolve db. benpiper. host, and it resolves to 172. 3. 1. 100. Great. Okay. Let's start up the web server again and this time we will point it to the database instance. I'm going to go ahead and hit my up arrow a few times here and I'm going to come all the way back here and do a -e DBHOSTNAME=db. benpiper. host and then hit Enter to run it. Now we have just one thing left to do, and that is to set up the VPC peering connection between these two VPCs. So let's jump over this time to the VPC dashboard. First things first, make sure that the Northern Virginia region is selected, which it is. Then at the VPC dashboard, at the bottom left side menu, click on Peering Connections. Now you can see I have a deleted peering connection here from when I was experimenting with all this. Let's go ahead and click Create Peering Connection. For the peering connection name tag, we'll go ahead and call this east-west. The requestor is going to be the r53-lab-vpc. Scroll down a bit. We are going to peer with another VPC in my account, but it is going to be in another region. That other region is, of course, going to be Northern California, us-west-1. Now the acceptor VPC, now if you notice I click in the field here, it does not give me a dropdown or anything, I have to actually provide the VPC ID myself, which I have conveniently available. You may have to go grab this, but you will have to paste it in there. Alright, once you have this, go ahead and click Create Peering Connection. Now let's switch over to the Northern California region. Now it brings us back to the Create Peering Connection screen here, let's go ahead and click on Peering Connections up here to go back one level, and we have one peering connection that is pending acceptance. Let's go ahead and select this one, go to the Actions menu, and then Accept Request. Are we sure we want to accept this? Yes we are very sure. Let's go ahead and accept it. Next we need to modify the route tables so that traffic can pass over the new peering connection. After we close this, on the left side menu, go ahead and click Route Tables, and we want to select the r53-lab-rt route table. Click on the Routes tab. Click the Edit button, and I have one black hole route here, let's just go ahead and get rid of that. Click on Add another route. And the destination is going to be 172. 3. 0. 0/16 and the peering connection is going to be pcx. Once we have that, click Save. Now let's go back to the Northern Virginia region again. And we need to adjust the route table here as well, so let's click on r53-lab-rt, click on the Routes tab, click the Edit button, add another route, and the destination is 172. 9. 0. 0/16 and we will select the east-west peering connection, and then Save. Okay one more thing, we need to update the security group so that web1-west can actually connect to db-east. Scroll down a bit on the left side menu and click on Security Groups. We'll go ahead and select r53-lab-sg, click the Inbound Rules tab, and then click Edit, and we'll add another rule here. This is going to be an SSH rule, port 22. And for the source, we're going to put 172. 9. 0. 0/16. For the description I'll just put west and then click Save. Okay that's it. Let's go ahead and open up another tab in Chrome. And here we're going to type web1-west. benpiper. host, and not only does it resolve db. benpiper. host to the correct internal IP, it also shows connected, which means it's established a TCP connection to db-east across our VPC peering connection.

Summary
Private hosted zones are a great way to avoid hard coding IP addresses in your applications without having to create publically available domain names. Here are a few things to keep in mind when dealing with hosted zones. The records you create can have any IP address in the resource data, they are not limited to private addresses. You can associate a single hosted zone with multiple VPCs and you can associate multiple private hosted zones with a single VPC, as long as the zone names are different. Lastly, not all routing policies are supported in private hosted zones. Alright, one more module to go in the course. In the next one, I'll show you the process for transferring an existing domain name from a third party registrar to the Route 53 registrar.

Transferring Existing Domain Names to Route 53
Module Introduction
Welcome back. In this module, you'll learn the process for transferring a domain name from a third party registrar to Route 53. Recall that earlier in the course, I showed you a diagram similar to this one. Right now we're in the bottom left quadrant, we're using Route 53 for our DNS services, but we're using a third party registrar. When you transfer a domain name from a third party registrar to Route 53, you're moving from the bottom left quadrant to the upper left quadrant. After the transfer, route 53 will be both your registrar and your DNS provider. Transferring your domain name is what I call a pull process, as opposed to a push process. That is, Route 53 requests the transfer from the existing registrar. In order for this to happen, there are usually three things that you must do. First, registrars often use what's called a domain transfer lock, which prevents a domain name from being transferred. You must remove this lock before you can transfer the domain. Next, for some top level domains, you need an authorization code from your existing registrar. You provide this code to Route 53, and they use it essentially as a password to indicate that they are authorized to transfer the domain. Lastly, you'll need to disable any WHOIS privacy protection. When you register a domain, you provide contact information, but many registrars let you hide it from the public by enabling WHOIS privacy protection. You'll have to disable this feature before you can transfer your domain, just as with the process for updating the name servers, the specifics of unlocking the domain and getting the code depend on the registrar. Once you initiate the transfer, it can take up to 5 days to complete. This is precisely why I saved this lesson for the end of the course, because if you choose to transfer your existing domain name, there is a chance you won't be able to use it for up to 5 days.

Transferring a Domain Name
In this demo, I'll show you the process for transferring a domain name from an existing registrar to Route 53. First, I'll go to my registrar, unlock the domain, and get an authorization code. I'll then walk you through the transfer process from the Route 53 side. In the management console for my existing registrar, I'm at the domain management page for the domain name I want to transfer. I'm going to click on the Sharing and Transfer button up here, then I'm going to scroll all the way down to the bottom, and I see that the domain lock is on. I'm going to click the Unlock link here and that successfully unlocked it. Now that it's unlocked, I'm going to click the AUTH CODE button here, and it asks me why I'm transferring, I'll just click Send Code, and it makes me enter a valid reason, we'll click Other. Alright there we go. Now my registrar has emailed me the authorization code. I'm going to go ahead and jump back over to Route 53. Now here from the dashboard, to start the transfer process, on the left side menu, we'll click on Registered domains. Here click on the Transfer Domain button. And in the text field, go ahead and enter the domain name you want to transfer, benpiper. host. Now it gives you the pricing, which for the. host tld is $93. Alright, whoa, $93 huh. Alright, let's click on Check. Route 53 will check to see if the domain is locked. If it's locked, you won't be able to continue. If it's unlocked, which this one is, we can go down here and add the domain name to the cart. $93, wow. Alright, go ahead and click Continue here. Now on the next page, it prompts us to enter the authorization code. I'll go and pop it in there. Now we have to make a decision regarding the name servers. The first option lets us use the existing name servers, which as you recall, are the Route 53 name servers for the public hosted zone. The next option is to import the name servers from a Route 53 hosted zone that has the same name as the domain. Now we already have a public hosted zone with the same name as the domain and, in fact, it's using the same name servers that I just alluded to. So the first two options are effectively the same. The last option, specify new name servers to replace the current ones, is not recommended. Now you might do this if you wanted Route 53 to be your registrar, but not your DNS provider. As I said earlier, that is not what we're interested here in this course. The first option here is fine, so we'll go with that. Let us then scroll down and click Continue. Now on the next page, we provide our registrant contact information. Now if you scroll down to the very bottom, you have the option of hiding your contact information from the WHOIS database. This is free and comes standard with Route 53, so we'll take it. Let's go ahead and click Continue. Now on the final page, we get to review everything one last time, and if we scroll down, we must agree to the terms and conditions to complete the purchase. Since transferring this domain will cost $93, I'm not going to actually do it. But once you're at this point, you can click the Complete Purchase and off you go.

Summary
If you're already heavily invested in AWS, transferring your domains to Route 53 is a good way to consolidate costs. Not only that, having all of your DNS related management tools in one place is very convenient and greatly simplifies the process of adding and using new public hosted domains. Now the cost of a domain transfer depends on the top level domain. As we saw, the cost for the. host top level domain was $93, but for your. coms,. nets, and. orgs, it's much less, and for some domains, it's even free. Now the process for transferring a domain to Route 53 is a pull process, that is Route 53 initiates the transfer from the existing registrar. Once the process begins it can take up to 5 days for the transfer to complete. During that time you may be without use of your domain name.

Course Summary
Believe it not, you've reached the end of the course. Thank you so much for sticking with me and especially for your patience throughout some of the longer modules. We covered so much, so let's wrap up with a quick summary. Understanding DNS concepts and terms is key to understanding and using Route 53. AWS does not abstract away the core elements of DNS, and although most everything is behind a user friendly GUI, you still must know what the various DNS terms mean. Route 53 provides both public and private hosted zones. You have the freedom to use either or both. Domains you create in public hosted zones can be resolved by anyone on the internet. Domain names in a private hosted zone, on the other hand, can be resolved only from within the VPCs associated with that zone. You learned about the several different routing policies that really set Route 53 apart from other DNS providers. Simple, weighted, latency, failover, geolocation, geoproximity, and multivalue answer routing policies let you control name resolution in almost any way you can imagine. All of these routing policies, but one, can be combined with health checks, which can help avoid DNS black holes during server outages. Also, if you don't want to create and chain together routing policies manually, you can always using the traffic flow visual editor to easily generate traffic policies that you can then use in your hosted zones. Well that is it for this course. As always, if you have any questions feel free to visit the course discussion page on the Pluralsight website or send me an email at ben@benpiper. com. Until next time, I'm Ben Piper and thank you so much for watching.

Course Overview
Course Overview
Hi everyone, my name is Ben Piper, and welcome to my course AWS Networking Deep Dive: Route 53 DNS. I'm an AWS certified solutions architect and author. DNS, the domain name system, is the glue that holds the internet together. Amazon's Route 53 DNS service not only integrates seamlessly with other AWS offerings, but it also provides many powerful features that go above and beyond what you'll find with most DNS providers. In this course, you'll learn how to use Route 53 with any domain name, even if it's already registered with a different provider. You'll learn how to control traffic to your resources using DNS based routing policies that consider things such as resource health, network latency, geographic location, and more. Some of the major topics that we'll cover include, but certainly are not limited to, using an existing domain name with Route 53, registering a new domain name, health checks and failover routing policies, DNS-based load-balancing and geolocation, and private hosted zones for use with Amazon VPCs. By the end of this course, you'll known how to configure Route 53 for any situation and how to use it with any domain name. Before beginning the course, you should be familiar with creating VPCs and managing AWS instances. I hope you'll join me on this journey to learn DNS with the AWS Networking Deep Dive: Route 53 DNS course, only at Pluralsight.